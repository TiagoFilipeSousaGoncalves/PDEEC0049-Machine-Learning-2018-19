{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python function to compute the predictions according to the mean Euclidean distance to the sample points of each class.\n",
    "The function should have the following interface function [prediction] = meanPrediction(dataClass1, dataClass2, dataUnknownClass) where dataClass1 is an array N1xd; dataClass2 is an array N2xd; dataUnknownClass is an array Ntxd; and prediction is an array Ntx1. d is the dimension of the features.\n",
    "\n",
    "a)Determine the training error on your samples using only the x1 feature value. Make use of the function meanPrediction you wrote.\n",
    "\n",
    "b) Repeat but now use two feature values, x1 and x2.\n",
    "\n",
    "c) Repeat but use all three feature values.\n",
    "\n",
    "d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Implement Euclidean Distance Function First\n",
    "def euclidean_distance(a, b):\n",
    "    # Computes and returns the Euclidean distance between vectors 'a' and 'b'\n",
    "    distance = np.sqrt(np.sum(np.square(a-b)))\n",
    "    return distance\n",
    "\n",
    "#Let's implement k-NN Algorithm First\n",
    "#k-NN is lazy algorithm that memorizes data, so we can create a function that does that:\n",
    "def train(X_train, y_train):\n",
    "    # do nothing \n",
    "    return\n",
    "\n",
    "#Then, let's create a function that will generate our predictions:\n",
    "def predict(X_train, y_train, x_test, k):\n",
    "    # create list for distances and targets\n",
    "    distances = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        # first we compute the euclidean distance\n",
    "        distance = np.sqrt(np.sum(np.square(x_test - X_train[i, :])))\n",
    "        # add it to list of distances\n",
    "        distances.append([distance, i])\n",
    "\n",
    "    # sort the list\n",
    "    distances = sorted(distances)\n",
    "\n",
    "    # make a list of the k neighbors' targets\n",
    "    for i in range(k):\n",
    "        index = distances[i][1]\n",
    "        targets.append(y_train[index])\n",
    "\n",
    "    # return most common target\n",
    "    return Counter(targets).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "#We can also creat a k-NN complete algorithm that loops all over observation and makes a prediction\n",
    "def kNearestNeighbor(X_train, y_train, X_test, predictions, k):\n",
    "    # train on the input data\n",
    "    train(X_train, y_train)\n",
    "\n",
    "    # loop over all observations\n",
    "    for i in range(len(X_test)):\n",
    "        predictions.append(predict(X_train, y_train, X_test[i, :], k))\n",
    "\n",
    "#Let's creat a function to determine the accuracy of our algorithm\n",
    "def knn_accuracy(y_test, y_pred):\n",
    "    #Number of corrected predictions\n",
    "    corr = int(np.sum(y_test==y_pred))\n",
    "    n_samples = int(y_test.shape[0])\n",
    "    acc = corr/n_samples\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function based on Euclidean Distance: k-Nearest Neighbours (kNN)\n",
    "def meanPrediction(dataClass1, dataClass2, dataUnknownClass):\n",
    "    y_pred = []\n",
    "    bothClasses = np.concatenate((dataClass1, dataClass2), axis=0)\n",
    "    x_train = bothClasses[:, 0:-1]\n",
    "    y_train = bothClasses[:, -1]\n",
    "    x_test = dataUnknownClass\n",
    "    \n",
    "    #We use k = 7\n",
    "    kNearestNeighbor(x_train, y_train, dataUnknownClass, y_pred, 5)\n",
    "    \n",
    "    #Get to know the predicted Class\n",
    "    classe = Counter(y_pred).most_common(1)[0][0]\n",
    "    \n",
    "    if classe == 1.0:\n",
    "        classe = \"Class 1\"\n",
    "    else:\n",
    "        classe = \"Class 2\"\n",
    "    \n",
    "    return y_pred, classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataClass1 is : \n",
      " [[-5.01 -8.12 -3.68  1.  ]\n",
      " [-5.43 -3.48  0.    1.  ]\n",
      " [ 1.08 -5.52 -1.66  1.  ]\n",
      " [ 0.86 -3.78 -4.11  1.  ]\n",
      " [-2.67 -0.63  7.39  1.  ]\n",
      " [ 4.94  3.29  2.08  1.  ]\n",
      " [-2.51  2.09 -2.59  1.  ]\n",
      " [-2.25 -2.13 -6.94  1.  ]\n",
      " [ 5.56  2.86 -2.26  1.  ]\n",
      " [ 1.03 -3.33  4.33  1.  ]] \n",
      "\n",
      "dataClass2 is : \n",
      " [[-0.91 -0.18 -0.05  2.  ]\n",
      " [ 1.3  -2.06 -3.53  2.  ]\n",
      " [-7.75 -4.54 -0.95  2.  ]\n",
      " [-5.47  0.5   3.92  2.  ]\n",
      " [ 6.14  5.72 -4.85  2.  ]\n",
      " [ 3.6   1.26  4.36  2.  ]\n",
      " [ 5.37 -4.63 -3.65  2.  ]\n",
      " [ 7.18  1.46 -6.66  2.  ]\n",
      " [-7.39  1.17  6.3   2.  ]\n",
      " [-7.5  -6.32 -0.31  2.  ]] \n",
      "\n",
      "dataUnknown is: \n",
      " [[0.42550031 0.7825875  0.72242943]\n",
      " [0.00476601 0.91322601 0.88352672]\n",
      " [0.1858035  0.86466387 0.07884447]\n",
      " [0.95658684 0.50152771 0.60731224]\n",
      " [0.11539862 0.10453945 0.22688833]\n",
      " [0.92743303 0.62950641 0.54063922]\n",
      " [0.27552617 0.74220187 0.61367779]\n",
      " [0.62321262 0.1596796  0.67305388]\n",
      " [0.89519391 0.75158757 0.93910095]\n",
      " [0.08853805 0.72470961 0.70616347]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataClass1 = np.zeros((10, 4))\n",
    "#Assign Values dataClass1\n",
    "dataClass1[0, 0] = -5.01\n",
    "dataClass1[0, 1] = -8.12\n",
    "dataClass1[0, 2] = -3.68\n",
    "\n",
    "dataClass1[1, 0] = -5.43\n",
    "dataClass1[1, 1] = -3.48\n",
    "dataClass1[2, 0] = 1.08\n",
    "dataClass1[2, 1] = -5.52\n",
    "dataClass1[2, 2] = -1.66\n",
    "\n",
    "dataClass1[3, 0] = 0.86\n",
    "dataClass1[3, 1] = -3.78\n",
    "dataClass1[3, 2] = -4.11\n",
    "\n",
    "dataClass1[4, 0] = -2.67\n",
    "dataClass1[4, 1] = -0.63\n",
    "dataClass1[4, 2] = 7.39\n",
    "\n",
    "dataClass1[5, 0] = 4.94\n",
    "dataClass1[5, 1] = 3.29\n",
    "dataClass1[5, 2] = 2.08\n",
    "\n",
    "dataClass1[6, 0] = -2.51\n",
    "dataClass1[6, 1] = 2.09\n",
    "dataClass1[6, 2] = -2.59\n",
    "\n",
    "dataClass1[7, 0] = -2.25\n",
    "dataClass1[7, 1] = -2.13\n",
    "dataClass1[7, 2] = -6.94\n",
    "\n",
    "dataClass1[8, 0] = 5.56\n",
    "dataClass1[8, 1] = 2.86\n",
    "dataClass1[8, 2] = -2.26\n",
    "\n",
    "dataClass1[9, 0] = 1.03\n",
    "dataClass1[9, 1] = -3.33\n",
    "dataClass1[9, 2] = 4.33\n",
    "\n",
    "#dataClass1 Label is 1\n",
    "dataClass1[:, 3] = 1\n",
    "\n",
    "\n",
    "dataClass2 = np.zeros((10, 4))\n",
    "#Assign Values to dataClass2\n",
    "dataClass2[0, 0] = -0.91\n",
    "dataClass2[0, 1] = -0.18\n",
    "dataClass2[0, 2] = -0.05\n",
    "\n",
    "dataClass2[1, 0] = 1.30\n",
    "dataClass2[1, 1] = -2.06\n",
    "dataClass2[1, 2] = -3.53\n",
    "\n",
    "dataClass2[2, 0] = -7.75\n",
    "dataClass2[2, 1] = -4.54\n",
    "dataClass2[2, 2] = -0.95\n",
    "\n",
    "dataClass2[3, 0] = -5.47\n",
    "dataClass2[3, 1] = 0.50\n",
    "dataClass2[3, 2] = 3.92\n",
    "\n",
    "dataClass2[4, 0] = 6.14\n",
    "dataClass2[4, 1] = 5.72\n",
    "dataClass2[4, 2] = -4.85\n",
    "\n",
    "dataClass2[5, 0] = 3.60\n",
    "dataClass2[5, 1] = 1.26\n",
    "dataClass2[5, 2] = 4.36\n",
    "\n",
    "dataClass2[6, 0] = 5.37\n",
    "dataClass2[6, 1] = -4.63\n",
    "dataClass2[6, 2] = -3.65\n",
    "\n",
    "dataClass2[7, 0] = 7.18\n",
    "dataClass2[7, 1] = 1.46\n",
    "dataClass2[7, 2] = -6.66\n",
    "\n",
    "dataClass2[8, 0] = -7.39\n",
    "dataClass2[8, 1] = 1.17\n",
    "dataClass2[8, 2] = 6.30\n",
    "\n",
    "dataClass2[9, 0] = -7.50\n",
    "dataClass2[9, 1] = -6.32\n",
    "dataClass2[9, 2] = -0.31\n",
    "\n",
    "#dataClass2 Label is 2\n",
    "dataClass2[:, 3] = 2\n",
    "\n",
    "#Print both datasets\n",
    "print(\"dataClass1 is : \\n\", dataClass1, '\\n')\n",
    "print(\"dataClass2 is : \\n\", dataClass2, '\\n')\n",
    "\n",
    "#Generate dataUnknownClass\n",
    "dataUnknown = np.random.rand(10,3)\n",
    "print(\"dataUnknown is: \\n\", dataUnknown, '\\n')\n",
    "\n",
    "#print(dataClass1.shape, dataClass2.shape, dataUnknown.shape)\n",
    "#print(np.concatenate((dataClass1, dataClass2), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values are:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Using 1 feature, accuracy is:  100.0 %\n",
      "Predicted values are:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Using 2 features, accuracy is:  100.0 %\n",
      "Predicted values are:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Using 3 features, accuracy is:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "#Test the accuracy of our algorithm with a simple train test-split using dataClass 1 as example\n",
    "#Just 1feature\n",
    "x_train = dataClass1[0:6, [0]]\n",
    "y_train = dataClass1[0:6, -1]\n",
    "x_test = dataClass1[5:10, [0]]\n",
    "y_test = dataClass1[5:10, -1]\n",
    "y_pred = []\n",
    "\n",
    "kNearestNeighbor(x_train, y_train, x_test, y_pred, 5)\n",
    "print(\"Predicted values are: \", y_pred)\n",
    "\n",
    "acc = knn_accuracy(y_test, y_pred)\n",
    "print(\"Using 1 feature, accuracy is: \", acc, \"%\")\n",
    "\n",
    "#Just 2feature\n",
    "x_train = dataClass1[0:6, [0,1]]\n",
    "y_train = dataClass1[0:6, -1]\n",
    "x_test = dataClass1[5:10, [0,1]]\n",
    "y_test = dataClass1[5:10, -1]\n",
    "y_pred = []\n",
    "\n",
    "kNearestNeighbor(x_train, y_train, x_test, y_pred, 5)\n",
    "print(\"Predicted values are: \", y_pred)\n",
    "\n",
    "acc = knn_accuracy(y_test, y_pred)\n",
    "print(\"Using 2 features, accuracy is: \", acc, \"%\")\n",
    "\n",
    "#Just 3feature\n",
    "x_train = dataClass1[0:6, [0,1,2]]\n",
    "y_train = dataClass1[0:6, -1]\n",
    "x_test = dataClass1[5:10, [0,1,2]]\n",
    "y_test = dataClass1[5:10, -1]\n",
    "y_pred = []\n",
    "\n",
    "kNearestNeighbor(x_train, y_train, x_test, y_pred, 5)\n",
    "print(\"Predicted values are: \", y_pred)\n",
    "\n",
    "acc = knn_accuracy(y_test, y_pred)\n",
    "print(\"Using 3 features, accuracy is: \", acc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classe is:  Class 1 with the following votes:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#Let's Predict the Unknown Class\n",
    "#Using Just 1 Feature\n",
    "dataClass1_1f = np.concatenate((dataClass1[:, [0]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass1)\n",
    "\n",
    "dataClass2_1f = np.concatenate((dataClass1[:, [0]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass2)\n",
    "\n",
    "dataUnknown_1f = dataUnknown[:, [0]]\n",
    "#print(dataUnknown)\n",
    "\n",
    "votes_1f, classe_1f = meanPrediction(dataClass1_1f, dataClass2_1f, dataUnknown_1f)\n",
    "\n",
    "print(\"Predicted classe is: \", classe_1f, \"with the following votes: \", votes_1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classe is:  Class 1 with the following votes:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#Using Just 2 Feature\n",
    "dataClass1_2f = np.concatenate((dataClass1[:, [0,1]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass1)\n",
    "\n",
    "dataClass2_2f = np.concatenate((dataClass1[:, [0,1]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass2)\n",
    "\n",
    "dataUnknown_2f = dataUnknown[:, [0]]\n",
    "#print(dataUnknown)\n",
    "\n",
    "votes_2f, classe_2f = meanPrediction(dataClass1_2f, dataClass2_2f, dataUnknown_2f)\n",
    "\n",
    "print(\"Predicted classe is: \", classe_2f, \"with the following votes: \", votes_2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classe is:  Class 2 with the following votes:  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "#Using Just 3 Features\n",
    "#Compute function\n",
    "votes_3f, classe_3f = meanPrediction(dataClass1, dataClass2, dataUnknown)\n",
    "\n",
    "print(\"Predicted classe is: \", classe_3f, \"with the following votes: \", votes_3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?\n",
      "\n",
      "Answer: Actually, that is one of the problems with this algorithm, i.e., the accuracy of k-NN can be severely degraded with high-dimension data because there is little difference between the nearest and furthest neighbour.\n",
      "Also, one of the suggestions in order to improve the algorithm is to implement dimensionality reduction techniques like PCA, prior to appplying k-NN and help make the distance metric more meaningful.\n"
     ]
    }
   ],
   "source": [
    "print(\"d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?\\n\")\n",
    "print(\"Answer: Actually, that is one of the problems with this algorithm, i.e., the accuracy of k-NN can be severely degraded with high-dimension data because there is little difference between the nearest and furthest neighbour.\\nAlso, one of the suggestions in order to improve the algorithm is to implement dimensionality reduction techniques like PCA, prior to appplying k-NN and help make the distance metric more meaningful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Peter is a very predictable man. When he uses his tablet, all he does is watch movies. He always watches until his battery dies. He is also a very meticulous man. He has kept logs of every time he has charged his tablet, which includes how long he charged his tablet for and how long he was able to watch movies for afterwards. Now, Peter wants to use this log to predict how long he will be able to watch movies for when he starts so that he can plan his activities after watching his movies accordingly.\n",
    "You will be able to access Peter’s tablet charging log by reading from the file “TabletTrainingdata.txt”. The training data file consists of 100 lines, each with 2 comma-separated numbers. The first number denotes the amount of time the tablet was charged and the second denotes the amount of time the battery lasted.\n",
    "Read an input (test case) from the console (stdin) representing the amount of time the tablet was charged and output to the console the amount of time you predict his battery will last.\n",
    "\n",
    "    #example to read test case\n",
    "    timeCharged = float(input().strip())\n",
    "    \n",
    "    #example to output\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Model\n",
    "#USING OUR OWN IMPLEMENTATION OF LINEAR REGRESSION: Method learned in class\n",
    "def polyRegression(data1D, yy, testData, degree):\n",
    "    xdata = [data1D**dd for dd in range (degree+1)]\n",
    "    xdata = np.concatenate(xdata, axis=1)\n",
    "    \n",
    "    ww = np.linalg.inv(np.dot(xdata.transpose(),xdata))\n",
    "    ww = np.dot(ww, xdata.transpose())\n",
    "    ww = np.dot(ww, yy)    \n",
    "    \n",
    "    xdata = [testData**dd for dd in range (degree+1)]\n",
    "    xdata = np.concatenate(xdata, axis=1)\n",
    "    pred = np.dot(xdata, ww)    \n",
    "    return pred, ww\n",
    "    \n",
    "        \n",
    "    \n",
    "data = np.genfromtxt('TabletTrainingdata.txt', delimiter=',')\n",
    "#print (np.shape(data))\n",
    "#print (type(data))\n",
    "#print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert charged time, in hours:\n",
      "5\n",
      "For  5.0   hours of charging, the battery will last about  8.008794164220959  hours.\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert charged time, in hours:\")\n",
    "timeCharged = float(input().strip())\n",
    "#I used as input: 5.0\n",
    "\n",
    "#We have \"virtual feature = 1\"\n",
    "testData = np.array([[1], [timeCharged]])\n",
    "\n",
    "prediction, model  = polyRegression(data[:,[0]], data[:,[-1]], testData, 4)\n",
    "#print (np.shape(pred))\n",
    "#print (type(pred))\n",
    "#plt.plot(testData, pred);\n",
    "#plt.plot(data[:,[0]], data[:,[-1]], 'o')\n",
    "#print (model)\n",
    "\n",
    "print(\"For \", float(timeCharged), \"  hours of charging, the battery will last about \", float(prediction[1]), \" hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert charged time, in hours:\n",
      "5\n",
      "For  5.0  hours of charging, the battery will last about  8.008794164220959  hours.\n"
     ]
    }
   ],
   "source": [
    "#Another way of solving this\n",
    "#Depending on the degree of polynome we can make a simple for cycle to use the weights and to multiply by our input:\n",
    "#SUM(weight(i)+input**(i))\n",
    "#print(model)\n",
    "pred = 0\n",
    "print(\"Insert charged time, in hours:\")\n",
    "timeCharged = float(input().strip())\n",
    "\n",
    "#We iterate through all the weights of the model\n",
    "for i in range(int(model.shape[0])):\n",
    "    pred += model[i]*(timeCharged**i)\n",
    "\n",
    "#Print prediction\n",
    "print(\"For \", timeCharged, \" hours of charging, the battery will last about \", float(pred), \" hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING sklearn\n",
      "Insert charged time, in hours:\n",
      "5\n",
      "For  5.0   hours of charging, the battery will last about  8.008794164217239  hours.\n"
     ]
    }
   ],
   "source": [
    "#USING SKLEARN\n",
    "print (\"USING sklearn\")\n",
    "\n",
    "data = np.genfromtxt('TabletTrainingdata.txt', delimiter=',')\n",
    "#print (np.shape(data))\n",
    "#print (type(data))\n",
    "#print (data)\n",
    "\n",
    "print(\"Insert charged time, in hours:\")\n",
    "timeCharged = float(input().strip())\n",
    "#I used as input: 5.0\n",
    "\n",
    "#We have \"virtual feature = 1\"\n",
    "testData = np.array([[1], [timeCharged]])\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(4), LinearRegression())\n",
    "model = model.fit(data[:,[0]], data[:,-1])\n",
    "\n",
    "prediction = model.predict(testData)\n",
    "#print (np.shape(pred))\n",
    "#print (type(pred))\n",
    "#plt.plot(testData, pred);\n",
    "#plt.plot(data[:,[0]], data[:,[-1]], 'o')\n",
    "#print (model)\n",
    "\n",
    "print(\"For \", float(timeCharged), \"  hours of charging, the battery will last about \", float(prediction[1]), \" hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiago Filipe Sousa Gonçalves | 5º Ano MIB | UP201607753"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
