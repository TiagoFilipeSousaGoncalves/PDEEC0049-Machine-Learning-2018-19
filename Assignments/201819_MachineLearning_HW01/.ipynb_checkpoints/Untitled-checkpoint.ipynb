{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python function to compute the predictions according to the mean Euclidean distance to the sample points of each class.\n",
    "The function should have the following interface function [prediction] = meanPrediction(dataClass1, dataClass2, dataUnknownClass) where dataClass1 is an array N1xd; dataClass2 is an array N2xd; dataUnknownClass is an array Ntxd; and prediction is an array Ntx1. d is the dimension of the features.\n",
    "\n",
    "a)Determine the training error on your samples using only the x1 feature value. Make use of the function meanPrediction you wrote.\n",
    "\n",
    "b) Repeat but now use two feature values, x1 and x2.\n",
    "\n",
    "c) Repeat but use all three feature values.\n",
    "\n",
    "d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from sklearn import metrics, preprocessing\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "#%%\n",
    "\n",
    "# Implement the euclidean_distance function here:\n",
    "def euclidean_distance(a, b):\n",
    "    # Computes and returns the Euclidean distance between vectors 'a' and 'b'\n",
    "    distance = np.sqrt(np.sum(np.square(a - b)))\n",
    "    return distance\n",
    "\n",
    "def mac_queen_initialisation(X, k):\n",
    "    centroids = np.zeros((k, X.shape[1]))\n",
    "    for cc in range(k):\n",
    "        index = np.random.randint(0, high=X.shape[0])\n",
    "        centroids[cc] = X[index]\n",
    "    return centroids\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# The Euclidean distance function can be used for k-Means clustering:\n",
    "def k_means(X, k=3, n_iterations=10):\n",
    "    # X is a N-by-M numpy array of N data points, each with M dimensions/features\n",
    "    # k is the number of clusters to compute (3 is the default value)\n",
    "    # n_iterations is the maximum number of iterations we want (100 is the default value)\n",
    "    \n",
    "    # First, we need to initialise the clusters.\n",
    "    # To simplify, we will use the MacQueen method, selecting 'k' random points of 'X' as initial centroids:\n",
    "    centroids = mac_queen_initialisation(X, k)\n",
    "    \n",
    "    # Keep a history of the centroids' movements:    \n",
    "    centroids_history = np.zeros((n_iterations+1, k, X.shape[1]))\n",
    "    centroids_history[0, :, :] = centroids\n",
    "    \n",
    "    # This will store the cluster membership of each data point in 'X':\n",
    "    membership = np.zeros((X.shape[0]))\n",
    "    \n",
    "    # The k_means algorithm is iterative. Start a loop here for 'n_iterations':\n",
    "    for ii in range(n_iterations):    \n",
    "        # In each loop, for each data point:\n",
    "        for index in range(X.shape[0]):\n",
    "            # Compute the Euclidean distance between the data point and each centroid:\n",
    "            distance = [euclidean_distance(X[index], cc) for cc in centroids]\n",
    "        \n",
    "            # Then, assign each data point to the cluster with the nearest centroid:\n",
    "            membership[index] = np.argmin(distance)\n",
    "        \n",
    "        # Now, recompute the centroids of each cluster, computing the mean of the cluster data points:\n",
    "        for cc in range(k):\n",
    "            centroids[cc] = np.mean(X[membership == cc], axis=0)\n",
    "        \n",
    "        centroids_history[ii+1, :, :] = centroids\n",
    "        \n",
    "    # Finally, return the clustering result:\n",
    "    return membership, centroids, centroids_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataClass1 is : \n",
      " [[-5.01 -8.12 -3.68]\n",
      " [-5.43 -3.48 -3.54]\n",
      " [ 1.08 -5.52 -1.66]\n",
      " [ 0.86 -3.78 -4.11]\n",
      " [-2.67 -0.63  7.39]\n",
      " [ 4.94  3.29  2.08]\n",
      " [-2.51  2.09 -2.59]\n",
      " [-2.25 -2.13 -6.94]\n",
      " [ 5.56  2.86 -2.26]\n",
      " [ 1.03 -3.33  4.33]] \n",
      "\n",
      "dataClass2 is : \n",
      " [[-0.91 -0.18 -0.05]\n",
      " [ 1.3  -2.06 -3.53]\n",
      " [-7.75 -4.54 -0.95]\n",
      " [-5.47  0.5   3.92]\n",
      " [ 6.14  5.72 -4.85]\n",
      " [ 3.6   1.26  4.36]\n",
      " [ 5.37 -4.63 -3.65]\n",
      " [ 7.18  1.46 -6.66]\n",
      " [-7.39  1.17  6.3 ]\n",
      " [-7.5  -6.32 -0.31]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataClass1 = np.zeros((10, 3))\n",
    "#Assign Values dataClass1\n",
    "dataClass1[0, 0] = -5.01\n",
    "dataClass1[0, 1] = -8.12\n",
    "dataClass1[0, 2] = -3.68\n",
    "\n",
    "dataClass1[1, 0] = -5.43\n",
    "dataClass1[1, 1] = -3.48\n",
    "dataClass1[1, 2] = -3.54\n",
    "\n",
    "dataClass1[2, 0] = 1.08\n",
    "dataClass1[2, 1] = -5.52\n",
    "dataClass1[2, 2] = -1.66\n",
    "\n",
    "dataClass1[3, 0] = 0.86\n",
    "dataClass1[3, 1] = -3.78\n",
    "dataClass1[3, 2] = -4.11\n",
    "\n",
    "dataClass1[4, 0] = -2.67\n",
    "dataClass1[4, 1] = -0.63\n",
    "dataClass1[4, 2] = 7.39\n",
    "\n",
    "dataClass1[5, 0] = 4.94\n",
    "dataClass1[5, 1] = 3.29\n",
    "dataClass1[5, 2] = 2.08\n",
    "\n",
    "dataClass1[6, 0] = -2.51\n",
    "dataClass1[6, 1] = 2.09\n",
    "dataClass1[6, 2] = -2.59\n",
    "\n",
    "dataClass1[7, 0] = -2.25\n",
    "dataClass1[7, 1] = -2.13\n",
    "dataClass1[7, 2] = -6.94\n",
    "\n",
    "dataClass1[8, 0] = 5.56\n",
    "dataClass1[8, 1] = 2.86\n",
    "dataClass1[8, 2] = -2.26\n",
    "\n",
    "dataClass1[9, 0] = 1.03\n",
    "dataClass1[9, 1] = -3.33\n",
    "dataClass1[9, 2] = 4.33\n",
    "\n",
    "\n",
    "dataClass2 = np.zeros((10, 3))\n",
    "#Assign Values to dataClass2\n",
    "dataClass2[0, 0] = -0.91\n",
    "dataClass2[0, 1] = -0.18\n",
    "dataClass2[0, 2] = -0.05\n",
    "\n",
    "dataClass2[1, 0] = 1.30\n",
    "dataClass2[1, 1] = -2.06\n",
    "dataClass2[1, 2] = -3.53\n",
    "\n",
    "dataClass2[2, 0] = -7.75\n",
    "dataClass2[2, 1] = -4.54\n",
    "dataClass2[2, 2] = -0.95\n",
    "\n",
    "dataClass2[3, 0] = -5.47\n",
    "dataClass2[3, 1] = 0.50\n",
    "dataClass2[3, 2] = 3.92\n",
    "\n",
    "dataClass2[4, 0] = 6.14\n",
    "dataClass2[4, 1] = 5.72\n",
    "dataClass2[4, 2] = -4.85\n",
    "\n",
    "dataClass2[5, 0] = 3.60\n",
    "dataClass2[5, 1] = 1.26\n",
    "dataClass2[5, 2] = 4.36\n",
    "\n",
    "dataClass2[6, 0] = 5.37\n",
    "dataClass2[6, 1] = -4.63\n",
    "dataClass2[6, 2] = -3.65\n",
    "\n",
    "dataClass2[7, 0] = 7.18\n",
    "dataClass2[7, 1] = 1.46\n",
    "dataClass2[7, 2] = -6.66\n",
    "\n",
    "dataClass2[8, 0] = -7.39\n",
    "dataClass2[8, 1] = 1.17\n",
    "dataClass2[8, 2] = 6.30\n",
    "\n",
    "dataClass2[9, 0] = -7.50\n",
    "dataClass2[9, 1] = -6.32\n",
    "dataClass2[9, 2] = -0.31\n",
    "\n",
    "#Print both datasets\n",
    "print(\"dataClass1 is : \\n\", dataClass1, '\\n')\n",
    "print(\"dataClass2 is : \\n\",dataClass2, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Peter is a very predictable man. When he uses his tablet, all he does is watch movies. He always watches until his battery dies. He is also a very meticulous man. He has kept logs of every time he has charged his tablet, which includes how long he charged his tablet for and how long he was able to watch movies for afterwards. Now, Peter wants to use this log to predict how long he will be able to watch movies for when he starts so that he can plan his activities after watching his movies accordingly.\n",
    "You will be able to access Peter’s tablet charging log by reading from the file “TabletTrainingdata.txt”. The training data file consists of 100 lines, each with 2 comma-separated numbers. The first number denotes the amount of time the tablet was charged and the second denotes the amount of time the battery lasted.\n",
    "Read an input (test case) from the console (stdin) representing the amount of time the tablet was charged and output to the console the amount of time you predict his battery will last.\n",
    "\n",
    "    #example to read test case\n",
    "    timeCharged = float(input().strip())\n",
    "    \n",
    "    #example to output\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#USING OUR OWN IMPLEMENTATION OF LINEAR REGRESSION\n",
    "def polyRegression(data1D, yy, testData, degree):\n",
    "    xdata = [data1D**dd for dd in range (degree+1)]\n",
    "    xdata = np.concatenate(xdata, axis=1)\n",
    "    \n",
    "    ww = np.linalg.inv(np.dot(xdata.transpose(),xdata))\n",
    "    ww = np.dot(ww, xdata.transpose())\n",
    "    ww = np.dot(ww, yy)    \n",
    "    \n",
    "    xdata = [testData**dd for dd in range (degree+1)]\n",
    "    xdata = np.concatenate(xdata, axis=1)\n",
    "    pred = np.dot(testData, ww)    \n",
    "    return pred, ww\n",
    "\n",
    "data = np.genfromtxt('TabletTrainingdata.txt', delimiter=',')\n",
    "print (np.shape(data))\n",
    "print (type(data))\n",
    "print (data)\n",
    "\n",
    "testData = np.array(float(input().strip()))\n",
    "testData = testData.reshape(1, -1)\n",
    "\n",
    "prediction, model  = polyRegression(data[:,[0]], data[:,[-1]], testData, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.shape(prediction))\n",
    "print (type(prediction))\n",
    "print(prediction)\n",
    "plt.plot(testData, prediction);\n",
    "plt.plot(data[:,[0]], data[:,[-1]], 'o')\n",
    "print (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING SKLEARN\n",
    "print (\"USING sklearn\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "data = np.genfromtxt('TabletTrainingdata.txt', delimiter=',')\n",
    "print (np.shape(data))\n",
    "print (type(data))\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = np.array(float(input().strip()))\n",
    "testData = testData.reshape(1, -1)\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(9), LinearRegression())\n",
    "model = model.fit(data[:,[0]], data[:,-1])\n",
    "pred = model.predict(testData)\n",
    "print (np.shape(pred))\n",
    "print (type(pred))\n",
    "\n",
    "plt.plot(testData, pred);\n",
    "plt.plot(data[:,[0]], data[:,[-1]], 'o')\n",
    "print (model)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
