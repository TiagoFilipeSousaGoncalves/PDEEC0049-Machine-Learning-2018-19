{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python function to compute the predictions according to the mean Euclidean distance to the sample points of each class.\n",
    "The function should have the following interface function [prediction] = meanPrediction(dataClass1, dataClass2, dataUnknownClass) where dataClass1 is an array N1xd; dataClass2 is an array N2xd; dataUnknownClass is an array Ntxd; and prediction is an array Ntx1. d is the dimension of the features.\n",
    "\n",
    "a)Determine the training error on your samples using only the x1 feature value. Make use of the function meanPrediction you wrote.\n",
    "\n",
    "b) Repeat but now use two feature values, x1 and x2.\n",
    "\n",
    "c) Repeat but use all three feature values.\n",
    "\n",
    "d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 12 11:37:57 2018\n",
    "\n",
    "@author: Tiago Flipe Sousa Gonçalves\n",
    "\"\"\"\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Implement Euclidean Distance Function First\n",
    "# Computes and returns the Euclidean distance between vectors 'a' and 'b'\n",
    "def euclidean_distance(UnknownClassElement, dataClass):\n",
    "    d=np.zeros((dataClass.shape[0],1))\n",
    "    for index in range(dataClass.shape[0]):\n",
    "        if dataClass.shape[1]==1:\n",
    "             d[index]=np.sqrt(np.power((dataUnknownClassELement-dataClass[index]),2))\n",
    "        else:\n",
    "             d[index]=np.sqrt(sum(np.power((dataUnknownClassElement-dataClass[index]),2)))\n",
    "             \n",
    "    return np.mean(d)\n",
    "\n",
    "#Implemten meanPrediction Function\n",
    "def meanPrediction(dataClass1, dataClass2, dataUnknownClass):\n",
    "    #Initialize Distance Arrays\n",
    "    dc1=np.zeros((dataUnknownClass.shape[0],1))\n",
    "    dc2=np.zeros((dataUnknownClass.shape[0],1))\n",
    "    predictions = np.zeros((dataUnknownClass.shape[0], 1))\n",
    "    \n",
    "    #Iterate from every dataUnknownClass item\n",
    "    for index in range(dataUnknownClass.shape[0]):\n",
    "        #Calculate distances from points to every class\n",
    "        dc1[index] = euclidean_distance(dataClass1, dataUnknownClass[index])\n",
    "        dc2[index] = euclidean_distance(dataClass2, dataUnknownClass[index])\n",
    "        \n",
    "        #Evaluate Classes based on the means\n",
    "        if np.mean(dc1[index]) < np.mean(dc2[index]):\n",
    "            predictions[index] = 1\n",
    "        elif np.mean(dc1[index]) > np.mean(dc2[index]):\n",
    "            predictions[index] = 2\n",
    "        else:\n",
    "            #In case the means are equal assign 1 by default:\n",
    "            predictions[index] = random.randint(1,2)\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "#Let's creat a function to determine the accuracy of our algorithm\n",
    "def accuracy(y_test, y_pred):\n",
    "    #Number of corrected predictions\n",
    "    corr = 0\n",
    "    for index in range(y_test.shape[0]):\n",
    "        if y_test[index] == y_pred[index]:\n",
    "            corr +=1 \n",
    "    #corr = int(np.sum(y_test==y_pred))\n",
    "    n_samples = int((y_test.shape[0]))\n",
    "    acc = corr/n_samples\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataClass1 is : \n",
      " [[-5.01 -8.12 -3.68  1.  ]\n",
      " [-5.43 -3.48  0.    1.  ]\n",
      " [ 1.08 -5.52 -1.66  1.  ]\n",
      " [ 0.86 -3.78 -4.11  1.  ]\n",
      " [-2.67 -0.63  7.39  1.  ]\n",
      " [ 4.94  3.29  2.08  1.  ]\n",
      " [-2.51  2.09 -2.59  1.  ]\n",
      " [-2.25 -2.13 -6.94  1.  ]\n",
      " [ 5.56  2.86 -2.26  1.  ]\n",
      " [ 1.03 -3.33  4.33  1.  ]] \n",
      "\n",
      "dataClass2 is : \n",
      " [[-0.91 -0.18 -0.05  2.  ]\n",
      " [ 1.3  -2.06 -3.53  2.  ]\n",
      " [-7.75 -4.54 -0.95  2.  ]\n",
      " [-5.47  0.5   3.92  2.  ]\n",
      " [ 6.14  5.72 -4.85  2.  ]\n",
      " [ 3.6   1.26  4.36  2.  ]\n",
      " [ 5.37 -4.63 -3.65  2.  ]\n",
      " [ 7.18  1.46 -6.66  2.  ]\n",
      " [-7.39  1.17  6.3   2.  ]\n",
      " [-7.5  -6.32 -0.31  2.  ]] \n",
      "\n",
      "dataUnknown is: \n",
      " [[-5.01 -8.12 -3.68  1.  ]\n",
      " [-5.43 -3.48  0.    1.  ]\n",
      " [ 1.08 -5.52 -1.66  1.  ]\n",
      " [ 0.86 -3.78 -4.11  1.  ]\n",
      " [-2.67 -0.63  7.39  1.  ]\n",
      " [ 4.94  3.29  2.08  1.  ]\n",
      " [-2.51  2.09 -2.59  1.  ]\n",
      " [-2.25 -2.13 -6.94  1.  ]\n",
      " [ 5.56  2.86 -2.26  1.  ]\n",
      " [ 1.03 -3.33  4.33  1.  ]\n",
      " [-0.91 -0.18 -0.05  2.  ]\n",
      " [ 1.3  -2.06 -3.53  2.  ]\n",
      " [-7.75 -4.54 -0.95  2.  ]\n",
      " [-5.47  0.5   3.92  2.  ]\n",
      " [ 6.14  5.72 -4.85  2.  ]\n",
      " [ 3.6   1.26  4.36  2.  ]\n",
      " [ 5.37 -4.63 -3.65  2.  ]\n",
      " [ 7.18  1.46 -6.66  2.  ]\n",
      " [-7.39  1.17  6.3   2.  ]\n",
      " [-7.5  -6.32 -0.31  2.  ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "dataClass1 = np.zeros((10, 4))\n",
    "#Assign Values dataClass1\n",
    "dataClass1[0, 0] = -5.01\n",
    "dataClass1[0, 1] = -8.12\n",
    "dataClass1[0, 2] = -3.68\n",
    "\n",
    "dataClass1[1, 0] = -5.43\n",
    "dataClass1[1, 1] = -3.48\n",
    "dataClass1[2, 0] = 1.08\n",
    "dataClass1[2, 1] = -5.52\n",
    "dataClass1[2, 2] = -1.66\n",
    "\n",
    "dataClass1[3, 0] = 0.86\n",
    "dataClass1[3, 1] = -3.78\n",
    "dataClass1[3, 2] = -4.11\n",
    "\n",
    "dataClass1[4, 0] = -2.67\n",
    "dataClass1[4, 1] = -0.63\n",
    "dataClass1[4, 2] = 7.39\n",
    "\n",
    "dataClass1[5, 0] = 4.94\n",
    "dataClass1[5, 1] = 3.29\n",
    "dataClass1[5, 2] = 2.08\n",
    "\n",
    "dataClass1[6, 0] = -2.51\n",
    "dataClass1[6, 1] = 2.09\n",
    "dataClass1[6, 2] = -2.59\n",
    "\n",
    "dataClass1[7, 0] = -2.25\n",
    "dataClass1[7, 1] = -2.13\n",
    "dataClass1[7, 2] = -6.94\n",
    "\n",
    "dataClass1[8, 0] = 5.56\n",
    "dataClass1[8, 1] = 2.86\n",
    "dataClass1[8, 2] = -2.26\n",
    "\n",
    "dataClass1[9, 0] = 1.03\n",
    "dataClass1[9, 1] = -3.33\n",
    "dataClass1[9, 2] = 4.33\n",
    "\n",
    "\n",
    "\n",
    "dataClass2 = np.zeros((10, 4))\n",
    "#Assign Values to dataClass2\n",
    "dataClass2[0, 0] = -0.91\n",
    "dataClass2[0, 1] = -0.18\n",
    "dataClass2[0, 2] = -0.05\n",
    "\n",
    "dataClass2[1, 0] = 1.30\n",
    "dataClass2[1, 1] = -2.06\n",
    "dataClass2[1, 2] = -3.53\n",
    "\n",
    "dataClass2[2, 0] = -7.75\n",
    "dataClass2[2, 1] = -4.54\n",
    "dataClass2[2, 2] = -0.95\n",
    "\n",
    "dataClass2[3, 0] = -5.47\n",
    "dataClass2[3, 1] = 0.50\n",
    "dataClass2[3, 2] = 3.92\n",
    "\n",
    "dataClass2[4, 0] = 6.14\n",
    "dataClass2[4, 1] = 5.72\n",
    "dataClass2[4, 2] = -4.85\n",
    "\n",
    "dataClass2[5, 0] = 3.60\n",
    "dataClass2[5, 1] = 1.26\n",
    "dataClass2[5, 2] = 4.36\n",
    "\n",
    "dataClass2[6, 0] = 5.37\n",
    "dataClass2[6, 1] = -4.63\n",
    "dataClass2[6, 2] = -3.65\n",
    "\n",
    "dataClass2[7, 0] = 7.18\n",
    "dataClass2[7, 1] = 1.46\n",
    "dataClass2[7, 2] = -6.66\n",
    "\n",
    "dataClass2[8, 0] = -7.39\n",
    "dataClass2[8, 1] = 1.17\n",
    "dataClass2[8, 2] = 6.30\n",
    "\n",
    "dataClass2[9, 0] = -7.50\n",
    "dataClass2[9, 1] = -6.32\n",
    "dataClass2[9, 2] = -0.31\n",
    "\n",
    "#Labels for Each Classes\n",
    "#dataClass1 Label is 1\n",
    "dataClass1[:, 3] = 1\n",
    "#dataClass2 Label is 2\n",
    "dataClass2[:, 3] = 2\n",
    "\n",
    "#dataUnknownClass is the concatenations of both classes:\n",
    "dataUnknown = np.concatenate((dataClass1, dataClass2), axis=0)\n",
    "\n",
    "#Print both datasets\n",
    "print(\"dataClass1 is : \\n\", dataClass1, '\\n')\n",
    "print(\"dataClass2 is : \\n\", dataClass2, '\\n')\n",
    "\n",
    "#Generate dataUnknownClass\n",
    "#dataUnknown = np.random.rand(10,3)\n",
    "print(\"dataUnknown is: \\n\", dataUnknown, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0c6f9c4b57ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataUnknown\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m      \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Using Just 1 Feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeanPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataClass1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataClass2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataUnknown\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0macc_1f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The accuracy with one feature is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_1f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" % \"\u001b[0m \u001b[1;34m\"with the following predictions: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-33dfa675e65b>\u001b[0m in \u001b[0;36mmeanPrediction\u001b[1;34m(dataClass1, dataClass2, dataUnknownClass)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataUnknownClass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m#Calculate distances from points to every class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mdc1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataClass1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataUnknownClass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mdc2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataClass2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataUnknownClass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-33dfa675e65b>\u001b[0m in \u001b[0;36meuclidean_distance\u001b[1;34m(UnknownClassElement, dataClass)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataClass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataClass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mdataClass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m              \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataUnknownClassELement\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdataClass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#Let's Predict the Unknown Class and check the training error\n",
    "y_test = np.array(dataUnknown[:, [-1]]      )\n",
    "#Using Just 1 Feature\n",
    "y_pred = meanPrediction(dataClass1[:, [0]], dataClass2[:, [0]], dataUnknown[:, [0]])\n",
    "acc_1f = accuracy(y_test=y_test, y_pred=y_pred)\n",
    "print(\"The accuracy with one feature is: \", acc_1f, \" % \" \"with the following predictions: \", y_pred)\n",
    "\n",
    "#Using Just 2 Feature\n",
    "#print(dataUnknown)\n",
    "y_pred = meanPrediction(dataClass1[:, 0:2], dataClass2[:, 0:2], dataUnknown[:, 0:2])\n",
    "acc_2f = accuracy(y_test=y_test, y_pred=y_pred)\n",
    "print(\"The accuracy with one feature is: \", acc_2f, \" % \" \"with the following predictions: \", y_pred)\n",
    "\n",
    "#Using Just 3 Features\n",
    "#Compute function\n",
    "y_pred = meanPrediction(dataClass1[:, 0:3], dataClass2[:, 0:3], dataUnknown[:,0:3])\n",
    "acc_3f = accuracy(y_test, y_pred)\n",
    "print(\"The accuracy with three features is \", acc_3f, \"% \" \"with the following predictions: \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c8c655161433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mkNearestNeighbor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted values are: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e8e7ffd126f7>\u001b[0m in \u001b[0;36mkNearestNeighbor\u001b[1;34m(X_train, y_train, X_test, predictions, k)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# loop over all observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#Let's creat a function to determine the accuracy of our algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e8e7ffd126f7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X_train, y_train, x_test, k)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# return most common target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 8 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "#Test the accuracy of our algorithm with a simple train test-split using dataClass 1 as example\n",
    "#Just 1feature\n",
    "x_train = dataClass1[:, [0]]\n",
    "y_train = dataClass1[0:6, -1]\n",
    "x_test = dataClass1[5:10, [0]]\n",
    "y_test = dataClass1[5:10, -1]\n",
    "y_pred = []\n",
    "\n",
    "kNearestNeighbor(x_train, y_train, x_test, y_pred, 5)\n",
    "print(\"Predicted values are: \", y_pred)\n",
    "\n",
    "acc = knn_accuracy(y_test, y_pred)\n",
    "print(\"Using 1 feature, accuracy is: \", acc, \"%\")\n",
    "\n",
    "#Just 2feature\n",
    "x_train = dataClass1[0:6, [0,1]]\n",
    "y_train = dataClass1[0:6, -1]\n",
    "x_test = dataClass1[5:10, [0,1]]\n",
    "y_test = dataClass1[5:10, -1]\n",
    "y_pred = []\n",
    "\n",
    "kNearestNeighbor(x_train, y_train, x_test, y_pred, 5)\n",
    "print(\"Predicted values are: \", y_pred)\n",
    "\n",
    "acc = knn_accuracy(y_test, y_pred)\n",
    "print(\"Using 2 features, accuracy is: \", acc, \"%\")\n",
    "\n",
    "#Just 3feature\n",
    "x_train = dataClass1[0:6, [0,1,2]]\n",
    "y_train = dataClass1[0:6, -1]\n",
    "x_test = dataClass1[5:10, [0,1,2]]\n",
    "y_test = dataClass1[5:10, -1]\n",
    "y_pred = []\n",
    "\n",
    "kNearestNeighbor(x_train, y_train, x_test, y_pred, 5)\n",
    "print(\"Predicted values are: \", y_pred)\n",
    "\n",
    "acc = knn_accuracy(y_test, y_pred)\n",
    "print(\"Using 3 features, accuracy is: \", acc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classe is:  Class 1 with the following votes:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "The accuracy with one feature is:  50.0\n"
     ]
    }
   ],
   "source": [
    "#Let's Predict the Unknown Class and check the training error\n",
    "#Using Just 1 Feature\n",
    "dataClass1_1f = np.concatenate((dataClass1[:, [0]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass1)\n",
    "\n",
    "dataClass2_1f = np.concatenate((dataClass1[:, [0]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass2)\n",
    "\n",
    "dataUnknown_1f = dataUnknown[:, [0]]\n",
    "y_test = dataUnknown[:, [-1]]\n",
    "#print(dataUnknown)\n",
    "\n",
    "votes_1f, classe_1f = meanPrediction(dataClass1_1f, dataClass2_1f, dataUnknown_1f)\n",
    "acc_1f = knn_accuracy(y_test=y_test, y_pred=votes_1f)\n",
    "\n",
    "print(\"Predicted classe is: \", classe_1f, \"with the following votes: \", votes_1f)\n",
    "print(\"The accuracy with one feature is: \", acc_1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classe is:  Class 1 with the following votes:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "The accuracy with one feature is:  50.0\n"
     ]
    }
   ],
   "source": [
    "#Using Just 2 Feature\n",
    "dataClass1_2f = np.concatenate((dataClass1[:, [0,1]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass1)\n",
    "\n",
    "dataClass2_2f = np.concatenate((dataClass1[:, [0,1]], dataClass1[:, [-1]]), axis=1)\n",
    "#print(dataClass2)\n",
    "\n",
    "dataUnknown_2f = dataUnknown[:, [0,1]]\n",
    "y_test = np.array(dataUnknown[:, [-1]])\n",
    "\n",
    "#print(dataUnknown)\n",
    "\n",
    "votes_2f, classe_2f = meanPrediction(dataClass1_2f, dataClass2_2f, dataUnknown_2f)\n",
    "accuracy_2f = knn_accuracy(votes_2f, y_test)\n",
    "\n",
    "print(\"Predicted classe is: \", classe_2f, \"with the following votes: \", votes_2f)\n",
    "print(\"The accuracy with one feature is: \", accuracy_2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-545845518d58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Using Just 3 Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Compute function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvotes_3f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasse_3f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeanPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataClass1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataClass2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataUnknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted classe is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasse_3f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"with the following votes: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvotes_3f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-bfe402310858>\u001b[0m in \u001b[0;36mmeanPrediction\u001b[1;34m(dataClass1, dataClass2, dataUnknownClass)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#We use k = 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mkNearestNeighbor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataUnknownClass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#Get to know the predicted Class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e8e7ffd126f7>\u001b[0m in \u001b[0;36mkNearestNeighbor\u001b[1;34m(X_train, y_train, X_test, predictions, k)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# loop over all observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#Let's creat a function to determine the accuracy of our algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e8e7ffd126f7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X_train, y_train, x_test, k)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# first we compute the euclidean distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m# add it to list of distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (3,) "
     ]
    }
   ],
   "source": [
    "#Using Just 3 Features\n",
    "#Compute function\n",
    "votes_3f, classe_3f = meanPrediction(dataClass1, dataClass2, dataUnknown)\n",
    "\n",
    "print(\"Predicted classe is: \", classe_3f, \"with the following votes: \", votes_3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?\n",
      "\n",
      "Answer: Actually, that is one of the problems with this algorithm, i.e., the accuracy of k-NN can be severely degraded with high-dimension data because there is little difference between the nearest and furthest neighbour.\n",
      "Also, one of the suggestions in order to improve the algorithm is to implement dimensionality reduction techniques like PCA, prior to appplying k-NN and help make the distance metric more meaningful.\n"
     ]
    }
   ],
   "source": [
    "print(\"d) Discuss your results. Is it ever possible for a finite set of data that the training error be larger for more data dimensions?\\n\")\n",
    "print(\"Answer: Actually, that is one of the problems with this algorithm, i.e., the accuracy of k-NN can be severely degraded with high-dimension data because there is little difference between the nearest and furthest neighbour.\\nAlso, one of the suggestions in order to improve the algorithm is to implement dimensionality reduction techniques like PCA, prior to appplying k-NN and help make the distance metric more meaningful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Peter is a very predictable man. When he uses his tablet, all he does is watch movies. He always watches until his battery dies. He is also a very meticulous man. He has kept logs of every time he has charged his tablet, which includes how long he charged his tablet for and how long he was able to watch movies for afterwards. Now, Peter wants to use this log to predict how long he will be able to watch movies for when he starts so that he can plan his activities after watching his movies accordingly.\n",
    "You will be able to access Peter’s tablet charging log by reading from the file “TabletTrainingdata.txt”. The training data file consists of 100 lines, each with 2 comma-separated numbers. The first number denotes the amount of time the tablet was charged and the second denotes the amount of time the battery lasted.\n",
    "Read an input (test case) from the console (stdin) representing the amount of time the tablet was charged and output to the console the amount of time you predict his battery will last.\n",
    "\n",
    "    #example to read test case\n",
    "    timeCharged = float(input().strip())\n",
    "    \n",
    "    #example to output\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Model\n",
    "#USING OUR OWN IMPLEMENTATION OF LINEAR REGRESSION: Method learned in class\n",
    "def polyRegression(data1D, yy, testData, degree):\n",
    "    xdata = [data1D**dd for dd in range (degree+1)]\n",
    "    xdata = np.concatenate(xdata, axis=1)\n",
    "    \n",
    "    ww = np.linalg.inv(np.dot(xdata.transpose(),xdata))\n",
    "    ww = np.dot(ww, xdata.transpose())\n",
    "    ww = np.dot(ww, yy)    \n",
    "    \n",
    "    xdata = [testData**dd for dd in range (degree+1)]\n",
    "    xdata = np.concatenate(xdata, axis=1)\n",
    "    pred = np.dot(xdata, ww)    \n",
    "    return pred, ww\n",
    "    \n",
    "        \n",
    "    \n",
    "data = np.genfromtxt('TabletTrainingdata.txt', delimiter=',')\n",
    "#print (np.shape(data))\n",
    "#print (type(data))\n",
    "#print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert charged time, in hours:\n",
      "5\n",
      "For  5.0   hours of charging, the battery will last about  8.008794164220959  hours.\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert charged time, in hours:\")\n",
    "timeCharged = float(input().strip())\n",
    "#I used as input: 5.0\n",
    "\n",
    "#We have \"virtual feature = 1\"\n",
    "testData = np.array([[1], [timeCharged]])\n",
    "\n",
    "prediction, model  = polyRegression(data[:,[0]], data[:,[-1]], testData, 4)\n",
    "#print (np.shape(pred))\n",
    "#print (type(pred))\n",
    "#plt.plot(testData, pred);\n",
    "#plt.plot(data[:,[0]], data[:,[-1]], 'o')\n",
    "#print (model)\n",
    "\n",
    "print(\"For \", float(timeCharged), \"  hours of charging, the battery will last about \", float(prediction[1]), \" hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert charged time, in hours:\n",
      "5\n",
      "For  5.0  hours of charging, the battery will last about  8.008794164220959  hours.\n"
     ]
    }
   ],
   "source": [
    "#Another way of solving this\n",
    "#Depending on the degree of polynome we can make a simple for cycle to use the weights and to multiply by our input:\n",
    "#SUM(weight(i)+input**(i))\n",
    "#print(model)\n",
    "pred = 0\n",
    "print(\"Insert charged time, in hours:\")\n",
    "timeCharged = float(input().strip())\n",
    "\n",
    "#We iterate through all the weights of the model\n",
    "for i in range(int(model.shape[0])):\n",
    "    pred += model[i]*(timeCharged**i)\n",
    "\n",
    "#Print prediction\n",
    "print(\"For \", timeCharged, \" hours of charging, the battery will last about \", float(pred), \" hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING sklearn\n",
      "Insert charged time, in hours:\n",
      "5\n",
      "For  5.0   hours of charging, the battery will last about  8.008794164217239  hours.\n"
     ]
    }
   ],
   "source": [
    "#USING SKLEARN\n",
    "print (\"USING sklearn\")\n",
    "\n",
    "data = np.genfromtxt('TabletTrainingdata.txt', delimiter=',')\n",
    "#print (np.shape(data))\n",
    "#print (type(data))\n",
    "#print (data)\n",
    "\n",
    "print(\"Insert charged time, in hours:\")\n",
    "timeCharged = float(input().strip())\n",
    "#I used as input: 5.0\n",
    "\n",
    "#We have \"virtual feature = 1\"\n",
    "testData = np.array([[1], [timeCharged]])\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(4), LinearRegression())\n",
    "model = model.fit(data[:,[0]], data[:,-1])\n",
    "\n",
    "prediction = model.predict(testData)\n",
    "#print (np.shape(pred))\n",
    "#print (type(pred))\n",
    "#plt.plot(testData, pred);\n",
    "#plt.plot(data[:,[0]], data[:,[-1]], 'o')\n",
    "#print (model)\n",
    "\n",
    "print(\"For \", float(timeCharged), \"  hours of charging, the battery will last about \", float(prediction[1]), \" hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiago Filipe Sousa Gonçalves | 5º Ano MIB | UP201607753"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
