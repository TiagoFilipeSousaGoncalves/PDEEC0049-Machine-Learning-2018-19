
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{HW5\_TiagoGoncalves}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{}Exercise 1}
        \PY{c+c1}{\PYZsh{}a) }
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k}{import} \PY{n}{KMeans}
        
        \PY{c+c1}{\PYZsh{}Load Data}
        \PY{n}{data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{genfromtxt}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heightWeightData.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{,}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}Split Data into Labels and Features}
        \PY{c+c1}{\PYZsh{}Convert labels into 0\PYZhy{}1}
        \PY{n}{labels} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
        \PY{c+c1}{\PYZsh{}Features}
        \PY{n}{features} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:}\PY{l+m+mi}{3}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{}Create Classifier K\PYZhy{}Means, with K=2}
        \PY{n}{kmeans} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}Obtain clusters with k\PYZhy{}means classifier}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fitting data....}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{kmeans}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{features}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}Make predictions on our data}
        \PY{c+c1}{\PYZsh{}Predictions}
        \PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{kmeans}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{features}\PY{p}{)}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}Compare predictions with ground truth}
        \PY{c+c1}{\PYZsh{}Count elements of class 0 in labels}
        \PY{n}{class\PYZus{}0} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{for} \PY{n}{label} \PY{o+ow}{in} \PY{n}{labels}\PY{p}{:}
            \PY{k}{if} \PY{n}{label}\PY{o}{==}\PY{l+m+mi}{0}\PY{p}{:}
                \PY{n}{class\PYZus{}0}\PY{o}{+}\PY{o}{=}\PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{}Count elements of class 0 in labels}
        \PY{n}{class\PYZus{}1} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{for} \PY{n}{label} \PY{o+ow}{in} \PY{n}{labels}\PY{p}{:}
            \PY{k}{if} \PY{n}{label}\PY{o}{==}\PY{l+m+mi}{1}\PY{p}{:}
                \PY{n}{class\PYZus{}1}\PY{o}{+}\PY{o}{=}\PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{}Count elements of class 0 in labels}
        \PY{n}{pred\PYZus{}0} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{for} \PY{n}{label} \PY{o+ow}{in} \PY{n}{y\PYZus{}hat}\PY{p}{:}
            \PY{k}{if} \PY{n}{label}\PY{o}{==}\PY{l+m+mi}{0}\PY{p}{:}
                \PY{n}{pred\PYZus{}0}\PY{o}{+}\PY{o}{=}\PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{}Count elements of class 0 in labels}
        \PY{n}{pred\PYZus{}1} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{for} \PY{n}{label} \PY{o+ow}{in} \PY{n}{y\PYZus{}hat}\PY{p}{:}
            \PY{k}{if} \PY{n}{label}\PY{o}{==}\PY{l+m+mi}{1}\PY{p}{:}
                \PY{n}{pred\PYZus{}1}\PY{o}{+}\PY{o}{=}\PY{l+m+mi}{1}
                
        \PY{c+c1}{\PYZsh{}Number of elements per class}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Elements per class in original data: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Class 0: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{class\PYZus{}0}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Class 1: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{class\PYZus{}1}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Elements per cluster in predictions: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Cluster 0: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{pred\PYZus{}0}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Cluster 1: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{pred\PYZus{}1}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{According to the results, one can say that K\PYZhy{}Means algorithm, with K=2 performs well, when compared with the clusters of our data.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Fitting data{\ldots}
Elements per class in original data:  
Class 0:  73 
Class 1:  137
Elements per cluster in predictions:  
Cluster 0:  138 
Cluster 1:  72
According to the results, one can say that K-Means algorithm, with K=2 performs well, when compared with the clusters of our data.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{}b)}
        \PY{c+c1}{\PYZsh{}New approach from: https://github.com/alexkimxyz/XMeans/blob/master/xmeans.py}
        
        \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{Implementation of XMeans algorithm based on}
        \PY{l+s+sd}{Pelleg, Dan, and Andrew W. Moore. \PYZdq{}X\PYZhy{}means: Extending K\PYZhy{}means with Efficient Estimation of the Number of Clusters.\PYZdq{}}
        \PY{l+s+sd}{ICML. Vol. 1. 2000.}
        \PY{l+s+sd}{https://www.cs.cmu.edu/\PYZti{}dpelleg/download/xmeans.pdf}
        \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k}{import} \PY{n}{KMeans}
        
        \PY{n}{EPS} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{finfo}\PY{p}{(}\PY{n+nb}{float}\PY{p}{)}\PY{o}{.}\PY{n}{eps}
        
        
        \PY{k}{def} \PY{n+nf}{loglikelihood}\PY{p}{(}\PY{n}{R}\PY{p}{,} \PY{n}{R\PYZus{}n}\PY{p}{,} \PY{n}{variance}\PY{p}{,} \PY{n}{M}\PY{p}{,} \PY{n}{K}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    See Pelleg\PYZsq{}s and Moore\PYZsq{}s for more details.}
        \PY{l+s+sd}{    :param R: (int) size of cluster}
        \PY{l+s+sd}{    :param R\PYZus{}n: (int) size of cluster/subcluster}
        \PY{l+s+sd}{    :param variance: (float) maximum likelihood estimate of variance under spherical Gaussian assumption}
        \PY{l+s+sd}{    :param M: (float) number of features (dimensionality of the data)}
        \PY{l+s+sd}{    :param K: (float) number of clusters for which loglikelihood is calculated}
        \PY{l+s+sd}{    :return: (float) loglikelihood value}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{k}{if} \PY{l+m+mi}{0} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{variance} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{EPS}\PY{p}{:}
                \PY{n}{res} \PY{o}{=} \PY{l+m+mi}{0}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{res} \PY{o}{=} \PY{n}{R\PYZus{}n} \PY{o}{*} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{R\PYZus{}n}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{R}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.5} \PY{o}{*} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{l+m+mi}{2} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{pi}\PY{p}{)} \PY{o}{+} \PY{n}{M} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{variance}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{0.5} \PY{o}{*} \PY{n}{K}
                \PY{k}{if} \PY{n}{res} \PY{o}{==} \PY{n}{np}\PY{o}{.}\PY{n}{inf}\PY{p}{:}
                    \PY{n}{res} \PY{o}{=} \PY{l+m+mi}{0}
            \PY{k}{return} \PY{n}{res}
        
        
        \PY{k}{def} \PY{n+nf}{get\PYZus{}additonal\PYZus{}k\PYZus{}split}\PY{p}{(}\PY{n}{K}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{clst\PYZus{}labels}\PY{p}{,} \PY{n}{clst\PYZus{}centers}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{p}{,} \PY{n}{K\PYZus{}sub}\PY{p}{,} \PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{)}\PY{p}{:}
            \PY{n}{bic\PYZus{}before\PYZus{}split} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{K}\PY{p}{)}
            \PY{n}{bic\PYZus{}after\PYZus{}split} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{K}\PY{p}{)}
            \PY{n}{clst\PYZus{}n\PYZus{}params} \PY{o}{=} \PY{n}{n\PYZus{}features} \PY{o}{+} \PY{l+m+mi}{1}
            \PY{n}{add\PYZus{}k} \PY{o}{=} \PY{l+m+mi}{0}
            \PY{k}{for} \PY{n}{clst\PYZus{}index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{K}\PY{p}{)}\PY{p}{:}
                \PY{n}{clst\PYZus{}points} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{clst\PYZus{}labels} \PY{o}{==} \PY{n}{clst\PYZus{}index}\PY{p}{]}
                \PY{n}{clst\PYZus{}size} \PY{o}{=} \PY{n}{clst\PYZus{}points}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                \PY{k}{if} \PY{n}{clst\PYZus{}size} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{K\PYZus{}sub}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} skip this cluster if it is too small}
                    \PY{c+c1}{\PYZsh{} i.e. cannot be split into more clusters}
                    \PY{k}{continue}
                \PY{n}{clst\PYZus{}variance} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{clst\PYZus{}points} \PY{o}{\PYZhy{}} \PY{n}{clst\PYZus{}centers}\PY{p}{[}\PY{n}{clst\PYZus{}index}\PY{p}{]}\PY{p}{)} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{2}\PY{p}{)} \PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{clst\PYZus{}size} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}
                \PY{n}{bic\PYZus{}before\PYZus{}split}\PY{p}{[}\PY{n}{clst\PYZus{}index}\PY{p}{]} \PY{o}{=} \PY{n}{loglikelihood}\PY{p}{(}\PY{n}{clst\PYZus{}size}\PY{p}{,} \PY{n}{clst\PYZus{}size}\PY{p}{,} \PY{n}{clst\PYZus{}variance}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{p}{,}
                                                             \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{clst\PYZus{}n\PYZus{}params} \PY{o}{/} \PY{l+m+mf}{2.0} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{clst\PYZus{}size}\PY{p}{)}
                \PY{n}{kmeans\PYZus{}subclst} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{n}{K\PYZus{}sub}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{clst\PYZus{}points}\PY{p}{)}
                \PY{n}{subclst\PYZus{}labels} \PY{o}{=} \PY{n}{kmeans\PYZus{}subclst}\PY{o}{.}\PY{n}{labels\PYZus{}}
                \PY{n}{subclst\PYZus{}centers} \PY{o}{=} \PY{n}{kmeans\PYZus{}subclst}\PY{o}{.}\PY{n}{cluster\PYZus{}centers\PYZus{}}
                \PY{n}{log\PYZus{}likelihood} \PY{o}{=} \PY{l+m+mi}{0}
                \PY{k}{for} \PY{n}{subclst\PYZus{}index} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{K\PYZus{}sub}\PY{p}{)}\PY{p}{:}
                    \PY{n}{subclst\PYZus{}points} \PY{o}{=} \PY{n}{clst\PYZus{}points}\PY{p}{[}\PY{n}{subclst\PYZus{}labels} \PY{o}{==} \PY{n}{subclst\PYZus{}index}\PY{p}{]}
                    \PY{n}{subclst\PYZus{}size} \PY{o}{=} \PY{n}{subclst\PYZus{}points}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                    \PY{k}{if} \PY{n}{subclst\PYZus{}size} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{K\PYZus{}sub}\PY{p}{:}
                        \PY{c+c1}{\PYZsh{} skip this subclst\PYZus{}size if it is too small}
                        \PY{c+c1}{\PYZsh{} i.e. won\PYZsq{}t be splittable into more clusters on the next iteration}
                        \PY{k}{continue}
                    \PY{n}{subclst\PYZus{}variance} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{subclst\PYZus{}points} \PY{o}{\PYZhy{}} \PY{n}{subclst\PYZus{}centers}\PY{p}{[}\PY{n}{subclst\PYZus{}index}\PY{p}{]}\PY{p}{)} \PY{o}{*}\PY{o}{*} \PY{l+m+mi}{2}\PY{p}{)} \PY{o}{/} \PY{n+nb}{float}\PY{p}{(}
                        \PY{n}{subclst\PYZus{}size} \PY{o}{\PYZhy{}} \PY{n}{K\PYZus{}sub}\PY{p}{)}
                    \PY{n}{log\PYZus{}likelihood} \PY{o}{=} \PY{n}{log\PYZus{}likelihood} \PY{o}{+} \PY{n}{loglikelihood}\PY{p}{(}\PY{n}{clst\PYZus{}size}\PY{p}{,} \PY{n}{subclst\PYZus{}size}\PY{p}{,} \PY{n}{subclst\PYZus{}variance}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{p}{,}
                                                                    \PY{n}{K\PYZus{}sub}\PY{p}{)}
                \PY{n}{subclst\PYZus{}n\PYZus{}params} \PY{o}{=} \PY{n}{K\PYZus{}sub} \PY{o}{*} \PY{n}{clst\PYZus{}n\PYZus{}params}
                \PY{n}{bic\PYZus{}after\PYZus{}split}\PY{p}{[}\PY{n}{clst\PYZus{}index}\PY{p}{]} \PY{o}{=} \PY{n}{log\PYZus{}likelihood} \PY{o}{\PYZhy{}} \PY{n}{subclst\PYZus{}n\PYZus{}params} \PY{o}{/} \PY{l+m+mf}{2.0} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{clst\PYZus{}size}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Count number of additional clusters that need to be created based on BIC comparison}
                \PY{k}{if} \PY{n}{bic\PYZus{}before\PYZus{}split}\PY{p}{[}\PY{n}{clst\PYZus{}index}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{n}{bic\PYZus{}after\PYZus{}split}\PY{p}{[}\PY{n}{clst\PYZus{}index}\PY{p}{]}\PY{p}{:}
                    \PY{n}{add\PYZus{}k} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
            \PY{k}{return} \PY{n}{add\PYZus{}k}
        
        
        \PY{k}{class} \PY{n+nc}{XMeans}\PY{p}{(}\PY{n}{KMeans}\PY{p}{)}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{kmax}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        :param kmax: maximum number of clusters that XMeans can divide the data in}
        \PY{l+s+sd}{        :param max\PYZus{}iter: maximum number of iterations for the `while` loop (hard limit)}
        \PY{l+s+sd}{        :param k\PYZus{}means\PYZus{}args: all other parameters supported by sklearn\PYZsq{}s KMeans algo (except `n\PYZus{}clusters`)}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                \PY{k}{if} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}clusters}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{in} \PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{:}
                    \PY{k}{raise} \PY{n+ne}{Exception}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{`n\PYZus{}clusters` is not an accepted parameter for XMeans algorithm}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                \PY{k}{if} \PY{n}{kmax} \PY{o}{\PYZlt{}} \PY{l+m+mi}{1}\PY{p}{:}
                    \PY{k}{raise} \PY{n+ne}{Exception}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{`kmax` cannot be less than 1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{KMax} \PY{o}{=} \PY{n}{kmax}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{max\PYZus{}iter} \PY{o}{=} \PY{n}{max\PYZus{}iter}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{k\PYZus{}means\PYZus{}args} \PY{o}{=} \PY{n}{k\PYZus{}means\PYZus{}args}
        
            \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
                \PY{n}{K} \PY{o}{=} \PY{l+m+mi}{1}
                \PY{n}{K\PYZus{}sub} \PY{o}{=} \PY{l+m+mi}{2}
                \PY{n}{K\PYZus{}old} \PY{o}{=} \PY{n}{K}
                \PY{n}{n\PYZus{}features} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                \PY{n}{stop\PYZus{}splitting} \PY{o}{=} \PY{k+kc}{False}
                \PY{n}{iter\PYZus{}num} \PY{o}{=} \PY{l+m+mi}{0}
                \PY{k}{while} \PY{o+ow}{not} \PY{n}{stop\PYZus{}splitting} \PY{o+ow}{and} \PY{n}{iter\PYZus{}num} \PY{o}{\PYZlt{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{max\PYZus{}iter}\PY{p}{:}
                    \PY{n}{K\PYZus{}old} \PY{o}{=} \PY{n}{K}
                    \PY{n}{kmeans} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{n}{K}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{)}
                    \PY{n}{clst\PYZus{}labels} \PY{o}{=} \PY{n}{kmeans}\PY{o}{.}\PY{n}{labels\PYZus{}}
                    \PY{n}{clst\PYZus{}centers} \PY{o}{=} \PY{n}{kmeans}\PY{o}{.}\PY{n}{cluster\PYZus{}centers\PYZus{}}
                    \PY{c+c1}{\PYZsh{} Iterate through all clusters and determine if further split is necessary}
                    \PY{n}{add\PYZus{}k} \PY{o}{=} \PY{n}{get\PYZus{}additonal\PYZus{}k\PYZus{}split}\PY{p}{(}\PY{n}{K}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{clst\PYZus{}labels}\PY{p}{,} \PY{n}{clst\PYZus{}centers}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{p}{,} \PY{n}{K\PYZus{}sub}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{)}
                    \PY{n}{K} \PY{o}{+}\PY{o}{=} \PY{n}{add\PYZus{}k}
                    \PY{c+c1}{\PYZsh{} stop splitting clusters when BIC stopped increasing or if max number of clusters in reached}
                    \PY{n}{stop\PYZus{}splitting} \PY{o}{=} \PY{n}{K\PYZus{}old} \PY{o}{==} \PY{n}{K} \PY{o+ow}{or} \PY{n}{K} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{KMax}
                    \PY{n}{iter\PYZus{}num} \PY{o}{=} \PY{n}{iter\PYZus{}num} \PY{o}{+} \PY{l+m+mi}{1}
                \PY{c+c1}{\PYZsh{} Run vanilla KMeans with the number of clusters determined above}
                \PY{n}{kmeans} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{n}{K\PYZus{}old}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{k\PYZus{}means\PYZus{}args}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{labels\PYZus{}} \PY{o}{=} \PY{n}{kmeans}\PY{o}{.}\PY{n}{labels\PYZus{}}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{cluster\PYZus{}centers\PYZus{}} \PY{o}{=} \PY{n}{kmeans}\PY{o}{.}\PY{n}{cluster\PYZus{}centers\PYZus{}}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{inertia\PYZus{}} \PY{o}{=} \PY{n}{kmeans}\PY{o}{.}\PY{n}{inertia\PYZus{}}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{n\PYZus{}clusters} \PY{o}{=} \PY{n}{K\PYZus{}old}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{}Create X\PYZhy{}Means Instance}
        \PY{n}{x\PYZus{}means} \PY{o}{=} \PY{n}{XMeans}\PY{p}{(}\PY{n}{kmax}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fitting data...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{x\PYZus{}means}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{features}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted labels: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{x\PYZus{}means}\PY{o}{.}\PY{n}{labels\PYZus{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted cluster centers: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{x\PYZus{}means}\PY{o}{.}\PY{n}{cluster\PYZus{}centers\PYZus{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted number of clusters: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{x\PYZus{}means}\PY{o}{.}\PY{n}{n\PYZus{}clusters}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Fitting data{\ldots}
Predicted labels: 
 [0 0 0 0 0 0 2 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 2 0 0
 0 2 0 0 1 0 0 1 1 0 1 0 0 2 0 0 2 1 2 1 0 0 0 1 0 2 0 0 0 0 1 1 0 0 2 1 1
 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 2 2 1 1 0 1 1 1 0 0 0 0
 1 0 0 0 0 1 2 1 0 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0
 0 0 1 1 1 0 0 2 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 2
 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1]
Predicted cluster centers: 
 [[163.83        57.36255469]
 [181.37072464  74.63976812]
 [188.15538462 106.31607692]]
Predicted number of clusters:  3

    \end{Verbatim}

    What's the criterion to choose the number of clusters?

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{To choose the best number of clusters, i.e. the best model, the authors proposed the BIC scoring.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Assuming that we have the data, D, and a a family of alternative models, Mj (where each solution corresponds to a different K value), in order to choose the best model, the posterior probabilities, P(Mj | D), are used to score the models.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{In this case, since all models are of the K\PYZhy{}Means assumed type (spherical Gaussians), to approximate the posteriors, up to normalization, they apply the BIC formula, from Kass and Wasserman (1995).}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{This is also known as the Schwarz criterion.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
To choose the best number of clusters, i.e. the best model, the authors proposed the BIC scoring.
Assuming that we have the data, D, and a a family of alternative models, Mj (where each solution corresponds to a different K value), in order to choose the best model, the posterior probabilities, P(Mj | D), are used to score the models.
In this case, since all models are of the K-Means assumed type (spherical Gaussians), to approximate the posteriors, up to normalization, they apply the BIC formula, from Kass and Wasserman (1995).
This is also known as the Schwarz criterion.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}b) Another approach that uses pyclustering library, that is based on another article.}
        \PY{c+c1}{\PYZsh{}In case of usage of pyclustering}
        \PY{c+c1}{\PYZsh{}!pip install pyclustering}
        
        \PY{k+kn}{from} \PY{n+nn}{pyclustering}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k}{import} \PY{n}{cluster\PYZus{}visualizer}
        \PY{k+kn}{from} \PY{n+nn}{pyclustering}\PY{n+nn}{.}\PY{n+nn}{cluster}\PY{n+nn}{.}\PY{n+nn}{xmeans} \PY{k}{import} \PY{n}{xmeans}
        \PY{k+kn}{from} \PY{n+nn}{pyclustering}\PY{n+nn}{.}\PY{n+nn}{cluster}\PY{n+nn}{.}\PY{n+nn}{center\PYZus{}initializer} \PY{k}{import} \PY{n}{kmeans\PYZus{}plusplus\PYZus{}initializer}
        \PY{k+kn}{from} \PY{n+nn}{pyclustering}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{read\PYZus{}sample}
        \PY{k+kn}{from} \PY{n+nn}{pyclustering}\PY{n+nn}{.}\PY{n+nn}{samples}\PY{n+nn}{.}\PY{n+nn}{definitions} \PY{k}{import} \PY{n}{SIMPLE\PYZus{}SAMPLES}
        \PY{c+c1}{\PYZsh{} Read sample \PYZsq{}simple3\PYZsq{} from file.}
        \PY{n}{sample} \PY{o}{=} \PY{n}{features}
        \PY{c+c1}{\PYZsh{} Prepare initial centers \PYZhy{} amount of initial centers defines amount of clusters from which X\PYZhy{}Means will}
        \PY{c+c1}{\PYZsh{} start analysis.}
        \PY{n}{amount\PYZus{}initial\PYZus{}centers} \PY{o}{=} \PY{l+m+mi}{2}
        \PY{n}{initial\PYZus{}centers} \PY{o}{=} \PY{n}{kmeans\PYZus{}plusplus\PYZus{}initializer}\PY{p}{(}\PY{n}{sample}\PY{p}{,} \PY{n}{amount\PYZus{}initial\PYZus{}centers}\PY{p}{)}\PY{o}{.}\PY{n}{initialize}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Create instance of X\PYZhy{}Means algorithm. The algorithm will start analysis from 2 clusters, the maximum}
        \PY{c+c1}{\PYZsh{} number of clusters that can be allocated is 20.}
        \PY{n}{xmeans\PYZus{}instance} \PY{o}{=} \PY{n}{xmeans}\PY{p}{(}\PY{n}{sample}\PY{p}{,} \PY{n}{initial\PYZus{}centers}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}
        \PY{n}{xmeans\PYZus{}instance}\PY{o}{.}\PY{n}{process}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Extract clustering results: clusters and their centers}
        \PY{n}{clusters} \PY{o}{=} \PY{n}{xmeans\PYZus{}instance}\PY{o}{.}\PY{n}{get\PYZus{}clusters}\PY{p}{(}\PY{p}{)}
        \PY{n}{centers} \PY{o}{=} \PY{n}{xmeans\PYZus{}instance}\PY{o}{.}\PY{n}{get\PYZus{}centers}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Visualize clustering results}
        \PY{n}{visualizer} \PY{o}{=} \PY{n}{cluster\PYZus{}visualizer}\PY{p}{(}\PY{p}{)}
        \PY{n}{visualizer}\PY{o}{.}\PY{n}{append\PYZus{}clusters}\PY{p}{(}\PY{n}{clusters}\PY{p}{,} \PY{n}{sample}\PY{p}{)}
        \PY{n}{visualizer}\PY{o}{.}\PY{n}{append\PYZus{}cluster}\PY{p}{(}\PY{n}{centers}\PY{p}{,} \PY{k+kc}{None}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{visualizer}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
