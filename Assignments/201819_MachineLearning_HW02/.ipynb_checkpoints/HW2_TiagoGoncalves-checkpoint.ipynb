{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regression\n",
    "\n",
    "Consider the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      " [[368.  15.]\n",
      " [340.  16.]\n",
      " [665.  25.]\n",
      " [954.  40.]\n",
      " [331.  15.]]\n",
      "\n",
      "Labels:  [1.7 1.5 2.8 5.  1.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([[368, 15, 1.7], [340, 16, 1.5], [665, 25, 2.8], [954, 40, 5.0], [331, 15, 1.3]])\n",
    "\n",
    "x_data = data[:, 0:2]\n",
    "y = data[:, 2]\n",
    "\n",
    "print(\"Features: \\n\", x_data)\n",
    "print(\"\\nLabels: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What’s the regression solution for f(y)=w1x1+w2x2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is:  f(y) =  0.0027731787719238003 x1 +  0.048757601172728926 x2\n"
     ]
    }
   ],
   "source": [
    "#Using Normal Equations Algorithm\n",
    "weights = np.linalg.inv(np.dot(x_data.transpose(), x_data))\n",
    "weights = np.dot(weights, x_data.transpose())\n",
    "weights = np.dot(weights, y)\n",
    "\n",
    "#Assuming no bias, so w0=0!\n",
    "print(\"Solution is: \", \"f(y) = \", str(weights[0]), \"x1 + \", str(weights[1]), \"x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution with bias is:  f(y) =  -0.6526112271325144  +  0.0009363257725659782 x1 +  0.11778650659623224 x2\n"
     ]
    }
   ],
   "source": [
    "#Assuming bias: Insert \"virtual feature\" = 1\n",
    "vf = np.array([1, 1, 1, 1, 1]).reshape(5,1)\n",
    "xdata = np.concatenate((vf, x_data), axis=1)\n",
    "\n",
    "#Using Normal Equations Algorithm\n",
    "weights = np.linalg.inv(np.dot(xdata.transpose(), xdata))\n",
    "weights = np.dot(weights, xdata.transpose())\n",
    "weights = np.dot(weights, y)\n",
    "\n",
    "\n",
    "print(\"Solution with bias is: \", \"f(y) = \", str(weights[0]), \" + \", str(weights[1]), \"x1 + \", str(weights[2]), \"x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Trying to improve the fitting, we collect another feature x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, features are: \n",
      " [[368.  15. 383.]\n",
      " [340.  16. 356.]\n",
      " [665.  25. 690.]\n",
      " [954.  40. 994.]\n",
      " [331.  15. 346.]]\n"
     ]
    }
   ],
   "source": [
    "x3_feature = np.array([383, 356, 690, 994, 346]).reshape(5, 1)\n",
    "new_xdata = np.concatenate((x_data, x3_feature), axis=1)\n",
    "\n",
    "print(\"Now, features are: \\n\", new_xdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s now the solution for f(y)=w1x1+w2x2+w3x3? Is it unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Normal Equations Algorithm\n",
    "weights = np.linalg.inv(np.dot(new_xdata.transpose(), new_xdata))\n",
    "weights = np.dot(weights, new_xdata.transpose())\n",
    "weights = np.dot(weights, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is:  f(y) =  -0.0018798828125000007 x1 +  0.03164062500000009 x2 +  0.009667968749999995 x3\n"
     ]
    }
   ],
   "source": [
    "#Assuming no bias, so w0=0!\n",
    "print(\"Solution is: \", \"f(y) = \", str(weights[0]), \"x1 + \", str(weights[1]), \"x2 + \", str(weights[2]), \"x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is:  f(y) =  38.695953670989084  +  -0.044042968749999994 x1 +  0.09824218750000013 x2 +  0.006054687499999999 x3\n",
      "\n",
      "The solution is not unique if we take into account: \n",
      "a) If we assume, or not, the existence of bias; \n",
      "b) If we use another algorithm to compute weights, such as Least-Mean-Square (LMS) or Steepest Descent;\n",
      "c) If the inverse of (X.T * X) doesn't exist, one could not use the Normal Equations Algorithm.\n"
     ]
    }
   ],
   "source": [
    "#Assuming bias: Insert \"virtual feature\" = 1\n",
    "xdata = np.concatenate((vf, new_xdata), axis=1)\n",
    "\n",
    "#Using Normal Equations Algorithm\n",
    "weights = np.linalg.inv(np.dot(xdata.transpose(), xdata))\n",
    "weights = np.dot(weights, xdata.transpose())\n",
    "weights = np.dot(weights, y)\n",
    "\n",
    "\n",
    "print(\"Solution is: \", \"f(y) = \", str(weights[0]), \" + \", str(weights[1]), \"x1 + \", str(weights[2]), \"x2 + \", str(weights[3]), \"x3\")\n",
    "\n",
    "print(\"\\nThe solution is not unique if we take into account:\", \"\\na) If we assume, or not, the existence of bias;\",\n",
    "     \"\\nb) If we use another algorithm to compute weights, such as Least-Mean-Square (LMS) or Steepest Descent;\"\n",
    "     \"\\nc) If the inverse of (X.T * X) doesn't exist, one could not use the Normal Equations Algorithm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification\n",
    "\n",
    "2. Consider the data in ’heightWeightData.txt’. The first column is the class label\n",
    "(1=male, 2=female), the second column is height, the third weight.\n",
    "\n",
    "a) Write a Matlab/Python function to model each class data as follows: assuming that\n",
    "height and weight are independent given the class, model the height using a histogram\n",
    "with bins breakpoints at every 10 cm (10, 20, 30, …, 170, 180, 190, …) and the weight\n",
    "with a Gaussian distribution with the mean and variance learnt from the data using\n",
    "maximum likelihood estimation.\n",
    "\n",
    "You can use suitable functions in Matlab/Python like histcounts. The function should\n",
    "receive as input the training data and the test data, making prediction (male/female)\n",
    "for the test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Functions\n",
    "#Modelling Height\n",
    "def height_model(heights_total, height_input):\n",
    "    bins = []\n",
    "    for i in range(int(height_input.min()), int(height_input.max()), 10):\n",
    "        bins.append(i)\n",
    "        #print(\"Bins : \", bins)\n",
    "        \n",
    "    hist, bin_edges = np.histogram(heights_total, bins=bins, density=True)\n",
    "    return hist, bin_edges\n",
    "\n",
    "#Plotting Height Histogram\n",
    "#plt.hist(height, bins=bins, density=True)  # arguments are passed to np.histogram\n",
    "#plt.title(\"Height Histograms\")\n",
    "#plt.show()\n",
    "\n",
    "#Modelling Weight\n",
    "def weight_model(weight_input, weight_input_mean, weight_input_var):\n",
    "    ll_weight = norm.pdf(weight_input, weight_input_mean, weight_input_var)\n",
    "    return ll_weight\n",
    "\n",
    "#print(height_model(male_heights))\n",
    "#print(height_model(female_heights))\n",
    "\n",
    "#print(weight_model(male_weights))\n",
    "#print(weight_model(female_weights))\n",
    "\n",
    "#print(prob_female)\n",
    "#print(prob_male)\n",
    "\n",
    "#Check Bin Location\n",
    "def check_bin(h_input, bin_edges):\n",
    "    diffs = []\n",
    "    for edge in range(len(bin_edges)):\n",
    "        diffs.append(abs((bin_edges[edge] - h_input))) \n",
    "    \n",
    "    min_diff = np.min(diffs)\n",
    "    \n",
    "    for i in range(len(diffs)):\n",
    "        if diffs[i] == min_diff:\n",
    "            index = i\n",
    "    \n",
    "    if index == (len(bin_edges) - 1):\n",
    "        index -=1\n",
    "    \n",
    "    return index\n",
    "\n",
    "#Computing Posterior Probability\n",
    "def prediction(class_probabilities, prior_probability):\n",
    "    predict = class_probabilities * prior_probability\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Functions\n",
    "def classification(training_data, test_data):\n",
    "    labels = training_data[:,0]\n",
    "    #Normalize labels: 0=male; 1=female\n",
    "    labels = labels-1\n",
    "    \n",
    "    #Get number of males and females in data\n",
    "    nr_males = 0\n",
    "    nr_females = 0\n",
    "    \n",
    "    for i in labels:\n",
    "        if i==0:\n",
    "            nr_males +=1\n",
    "        elif i==1:\n",
    "            nr_females +=1\n",
    "    \n",
    "    #print(nr_males, nr_females)\n",
    "    \n",
    "    #Get male and female indexes\n",
    "    male_index = []\n",
    "    female_index = []\n",
    "    for index in range(int(labels.shape[0])):\n",
    "        if labels[index] == 0:\n",
    "            male_index.append(index)\n",
    "        elif labels[index] == 1:\n",
    "            female_index.append(index)\n",
    "\n",
    "\n",
    "    #Features\n",
    "    height = training_data[:, 1]\n",
    "    weight = training_data[:, 2]\n",
    "\n",
    "    #Female Features\n",
    "    female_heights = height[female_index]\n",
    "    female_weights = weight[female_index]\n",
    "    #Male Features\n",
    "    male_heights = height[male_index]\n",
    "    male_weights = weight[male_index]\n",
    "    \n",
    "    #Prior Distribution\n",
    "    #Compute Prior Probabilities in each class\n",
    "    #prob_female = (nr_females/(nr_females+nr_males))\n",
    "    #prob_male = (nr_males/(nr_females+nr_males))\n",
    "    #Let's Assume Equal Prior Probabilities\n",
    "    prob_female = 0.5\n",
    "    prob_male = 0.5\n",
    "    \n",
    "    #Save previous info's in arrays\n",
    "    weight_input_means = [np.average(male_weights), np.average(female_weights)]\n",
    "    weight_input_var =  [np.var(male_weights), np.var(female_weights)]\n",
    "    #Weight input mean & var\n",
    "    weight_mean = np.average(weight)\n",
    "    weight_var = np.var(weight)\n",
    "    \n",
    "    #Evaluate Weight Likelihood\n",
    "    mw = weight_model(weight_input=test_data[1], weight_input_mean=weight_input_means[0], weight_input_var=weight_input_var[0])\n",
    "    fw = weight_model(weight_input=test_data[1], weight_input_mean=weight_input_means[1], weight_input_var=weight_input_var[0])\n",
    "    \n",
    "    #Evaluate Height\n",
    "    #Male\n",
    "    male_hist, male_bin_edges = height_model(heights_total=height, height_input=male_heights)\n",
    "    male_bin_index = check_bin(bin_edges=male_bin_edges, h_input=test_data[0])\n",
    "    mh = male_hist[male_bin_index]\n",
    "    #Female\n",
    "    female_hist, female_bin_edges = height_model(heights_total=height, height_input=female_heights)\n",
    "    female_bin_index = check_bin(bin_edges=female_bin_edges, h_input=test_data[0])\n",
    "    fh = female_hist[female_bin_index]\n",
    "    \n",
    "    #Class Probs\n",
    "    class_probs = [mh*mw, fh*fw]\n",
    "    #Compute Naive Bayes\n",
    "    #Male\n",
    "    male_pred = prediction(class_probabilities=class_probs[0], prior_probability=prob_male)\n",
    "    female_pred = prediction(class_probabilities=class_probs[1], prior_probability=prob_female)\n",
    "    \n",
    "    #Classify\n",
    "    if male_pred > female_pred:\n",
    "        pred_class = 0\n",
    "    elif female_pred > male_pred:\n",
    "        pred_class = 1\n",
    "    \n",
    "    return pred_class, male_pred, female_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the previous function to make predictions (male / female) for the following test\n",
    "points:\n",
    "\n",
    "[165 80]t, [181 65]t, [161 57]t and [181 77]t.\n",
    "\n",
    "c) What’s the estimated p([165 80]t | male)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [0, 1, 0, 1]\n",
      "The estimated p([165 80] | male) is:  4.184096006667823e-05\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "data = np.genfromtxt('heightWeightData.txt', delimiter=',')\n",
    "test_1 = [165, 80]\n",
    "test_2 = [181, 65]\n",
    "test_3 = [161, 57]\n",
    "test_4 = [181, 77]\n",
    "test = [test_1, test_2, test_3, test_4]\n",
    "predictions = []\n",
    "male_probs = []\n",
    "female_probs = []\n",
    "for point in test:\n",
    "    pred, male, female = classification(training_data=data, test_data=point)\n",
    "    predictions.append(pred)\n",
    "    male_probs.append(male)\n",
    "    female_probs.append(female)\n",
    "    \n",
    "print(\"Predictions: \", predictions)\n",
    "print(\"The estimated p([165 80] | male) is: \", male_probs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentals\n",
    "\n",
    "3. An experiment consists in randomly choosing values between 0 and 1 (a scalar in [0,1]) until the sum of the observed values is above 1.\n",
    "\n",
    "a) In python/matlab simulate the execution of 1000000 experiments. What’s the\n",
    "estimated number of values one needs to pick until the sum exceeds one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(number_of_experiments):\n",
    "    experiments = []\n",
    "    \n",
    "    for i in range(number_of_experiments):\n",
    "        counts = 0\n",
    "        sum = 0\n",
    "        \n",
    "        while counts <= 1000000 and sum <=1:\n",
    "            sum += np.random.random_sample()\n",
    "            counts += 1\n",
    "        experiments.append(counts)\n",
    "    \n",
    "    return np.array(experiments), np.mean(np.array(experiments)), np.around(np.mean(np.array(experiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1000000 experiments: \n",
      "Mean number of values is:  2.71905 \n",
      "So, the rounded estimated number of values one needs to pick would be:  3.0\n"
     ]
    }
   ],
   "source": [
    "exp_array, mean_nr_values, rounded_nr_values = experiment(1000000)\n",
    "\n",
    "print(\"For 1000000 experiments:\", \"\\nMean number of values is: \", mean_nr_values, \"\\nSo, the rounded estimated number of values one needs to pick would be: \", rounded_nr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, hist_edges = np.histogram(a=exp_array, bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) [1 point only in 20] Compute analytically the expected value of the number of values one needs to pick until the sum exceeds one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute probs P(X = x)\n",
    "probs = []\n",
    "for number in hist:\n",
    "    prob = number/1000000\n",
    "    probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X = 0) is: 0.0\n",
      "P(X = 1) is: 0.0\n",
      "P(X = 2) is: 0.498649\n",
      "P(X = 3) is: 0.334737\n",
      "P(X = 4) is: 0.125303\n",
      "P(X = 5) is: 0.033084\n",
      "P(X = 6) is: 0.006894\n",
      "P(X = 7) is: 0.001141\n",
      "P(X = 8) is: 0.000173\n",
      "P(X = 9) is: 1.6e-05\n",
      "P(X = 10) is: 3e-06\n",
      "P(X = 11) is: 0.0\n",
      "P(X = 12) is: 0.0\n",
      "P(X = 13) is: 0.0\n",
      "P(X = 14) is: 0.0\n",
      "P(X = 15) is: 0.0\n",
      "P(X = 16) is: 0.0\n",
      "P(X = 17) is: 0.0\n",
      "P(X = 18) is: 0.0\n",
      "P(X = 19) is: 0.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for prob in probs:\n",
    "    print(\"P(X = \"+str(i)+\") is:\", prob)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated number of values one needs to pick would be:  2.7190500000000006\n"
     ]
    }
   ],
   "source": [
    "#Compute Analytically - Nr_Of_Values = SUM xn*P(X|x=xn)\n",
    "nr_of_values = 0\n",
    "i = 0\n",
    "for prob in probs:\n",
    "    nr_of_values+= (prob * i)\n",
    "    i+=1\n",
    "\n",
    "print(\"The estimated number of values one needs to pick would be: \", nr_of_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
