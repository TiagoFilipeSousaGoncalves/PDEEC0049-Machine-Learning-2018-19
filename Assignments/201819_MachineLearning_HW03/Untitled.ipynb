{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the height/weight data from the file heightWeightData.txt. The first column is the class label (1=male, 2=female), the second column is height, the third weight. Start by replacing the weight column by the product of height and weight.\n",
    "\n",
    "For the Fisher’s linear discriminant analysis as discussed in the class, send the python/matlab code and answers for the following questions:\n",
    "\n",
    "a. What’s the SB matrix?\n",
    "\n",
    "b. What’s the SW matrix?\n",
    "\n",
    "c. What’s the optimal 1d projection direction?\n",
    "\n",
    "d. Project the data in the optimal 1d projection direction. Set the decision threshold as the middle point between the \n",
    "projected means. What’s the misclassification error rate?\n",
    "\n",
    "e. What’s your height and weight? What’s the model prediction for your case (male/female)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"heightWeightData.txt\", delimiter=\",\")\n",
    "\n",
    "#Weight is 3rd Column\n",
    "np.set_printoptions(suppress=True)\n",
    "new_data = np.zeros(data.shape)\n",
    "for i in range(int(new_data.shape[0])):\n",
    "    new_data[i, 0] = data[i, 0]\n",
    "    new_data[i, 1] = data[i, 1]\n",
    "    new_data[i, 2] = np.multiply(data[i, 1], data[i, 2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Vector for Males Class: \n",
      " [  182.01013699 14552.85501781] \n",
      "Mean Vector for Females Class: \n",
      " [ 165.28540146 9757.31728073]\n",
      "Between-Class Scatter Matrix, taking into account sample sizes:\n",
      " [[1.33211786e+04 3.81962480e+06]\n",
      " [3.81962480e+06 1.09521342e+09]]\n",
      "Between-Class Scatter Matrix, not regarding sample sizes:\n",
      " [[     152.84841103    43826.72132582]\n",
      " [   43826.72132582 12566578.14875751]]\n",
      "Within Class Scatter Matrix is:\n",
      " [[1.34819629e+04 2.38635072e+06]\n",
      " [2.38635072e+06 1.07660688e+09]]\n"
     ]
    }
   ],
   "source": [
    "#Implementing Fisher's Linear Discriminant Analysis\n",
    "#Let's group data first\n",
    "#Count males (=1) and females (=2)\n",
    "nr_males = 0\n",
    "nr_females = 0\n",
    "for i in range(int(new_data.shape[0])):\n",
    "    if new_data[i, 0] == 1:\n",
    "        nr_males+=1\n",
    "    elif new_data[i, 0] == 2:\n",
    "        nr_females+=1\n",
    "#print(nr_males, nr_females)\n",
    "#Concatenate Class Sizes\n",
    "class_sizes = np.array([nr_males, nr_females])\n",
    "\n",
    "#Assign Classes\n",
    "males = np.zeros([nr_males, new_data.shape[1]])\n",
    "females = np.zeros([nr_females, new_data.shape[1]])\n",
    "m_index = 0\n",
    "f_index = 0\n",
    "for index in range(int(new_data.shape[0])):\n",
    "    if new_data[index, 0] == 1:\n",
    "        males[m_index] = new_data[index]\n",
    "        m_index+=1\n",
    "    elif new_data[index, 0] == 2:\n",
    "        females[f_index] = new_data[index]\n",
    "        f_index+=1\n",
    "\n",
    "#Calculate means vector for each class\n",
    "#Drop Label Column\n",
    "f_males = males[:, 1:]\n",
    "f_females = females[:, 1:]\n",
    "#Calculate mean vector for each class\n",
    "mean_males = np.mean(a=f_males, axis=0)\n",
    "mean_females = np.mean(a=f_females, axis=0)\n",
    "\n",
    "print(\"Mean Vector for Males Class: \\n\", mean_males,\"\\nMean Vector for Females Class: \\n\", mean_females)\n",
    "\n",
    "#Calculate Overall Mean\n",
    "overall_mean = np.mean(new_data[:, 1:], axis=0)\n",
    "#print(overall_mean)\n",
    "\n",
    "#Let's Compute Between Class Scatter Matrix S_B\n",
    "#Concatenate Mean Vectors\n",
    "class_means = np.array([mean_males, mean_females])\n",
    "#Iterate through each class\n",
    "n_S_B = np.zeros((2,2))\n",
    "S_B = np.zeros((2,2))\n",
    "for i in range(2):\n",
    "    n_samples = class_sizes[i]\n",
    "    mean_of_class = class_means[i].reshape(2,1) #Reshape Mean Vectors into Column Vectors to perform Computation\n",
    "    ovrl_mean = overall_mean.reshape(2,1) #Reshape Overall Mean Vector into Column Vector to perform Computation\n",
    "    #Taking into account sample sizes\n",
    "    n_S_B += n_samples * (mean_of_class - ovrl_mean).dot((mean_of_class - ovrl_mean).T)\n",
    "    #Without sample sizes\n",
    "    S_B += (mean_of_class - ovrl_mean).dot((mean_of_class - ovrl_mean).T)\n",
    "\n",
    "#S_B Matrix\n",
    "print('Between-Class Scatter Matrix, taking into account sample sizes:\\n', n_S_B)\n",
    "print('Between-Class Scatter Matrix, not regarding sample sizes:\\n', S_B)\n",
    "\n",
    "\n",
    "#Let's Compute Within Class Scatter Matrix S_W\n",
    "#Calculate the scatter matrices for the SW (Scatter within) and sum the elements up\n",
    "#First reshape vectors to perform computations\n",
    "#Scatter Matrix for Males Class\n",
    "scatter_males = np.zeros((2, 2))\n",
    "for row in f_males:\n",
    "    row, mv = row.reshape(2,1), mean_males.reshape(2,1) # make column vectors\n",
    "    scatter_males += (row-mv).dot((row-mv).T)\n",
    "\n",
    "#Scatter Matrix for Females Class\n",
    "scatter_females = np.zeros((2, 2))\n",
    "for row in f_females:\n",
    "    row, mv = row.reshape(2,1), mean_females.reshape(2,1) #make column vectors\n",
    "    scatter_females += (row-mv).dot((row-mv).T)\n",
    "\n",
    "#Scatter Within Matrix is the sum of both of the Scatter Matrix above\n",
    "S_W = scatter_males + scatter_females # sum class scatter matrices\n",
    "print(\"Within Class Scatter Matrix is:\\n\", S_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvector 1: \n",
      "[[-0.99999392]\n",
      " [ 0.00348754]]\n",
      "Eigenvalue 1: 1.73e-18\n",
      "\n",
      "Eigenvector 2: \n",
      "[[-0.99999289]\n",
      " [-0.00377042]]\n",
      "Eigenvalue 2: 1.42e-02\n",
      "\n",
      "Everything was correctly calculated!\n"
     ]
    }
   ],
   "source": [
    "#Obtain the optimal 1D Projection Direction\n",
    "#Using S_B that takes into account the number of samples n_S_B\n",
    "#eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(n_S_B))\n",
    "\n",
    "#Using S_B that takes into account the number of samples n_S_B\n",
    "eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "\n",
    "for i in range(len(eig_vals)):\n",
    "    eigvec_sc = eig_vecs[:,i].reshape(2,1)   \n",
    "    print('\\nEigenvector {}: \\n{}'.format(i+1, eigvec_sc.real))\n",
    "    print('Eigenvalue {:}: {:.2e}'.format(i+1, eig_vals[i].real))\n",
    "    \n",
    "#Check the eigenvector-eigenvalue calculation\n",
    "for i in range(len(eig_vals)):\n",
    "    eigv = eig_vecs[:,i].reshape(2,1)\n",
    "    np.testing.assert_array_almost_equal(np.linalg.inv(S_W).dot(S_B).dot(eigv),\n",
    "                                         eig_vals[i] * eigv,\n",
    "                                         decimal=6, err_msg='', verbose=True)\n",
    "print('\\nEverything was correctly calculated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in decreasing order:\n",
      "\n",
      "0.014150392294159927\n",
      "1.734723475976807e-18\n",
      "Matrix W is: \n",
      " [-0.99999289 -0.00377042]\n"
     ]
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "\n",
    "print('Eigenvalues in decreasing order:\\n')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "# take the first eigvector, i.e. the most informative one \n",
    "#since we have two dimensions and only want one, due to the fact that is the optimal 1D-Projection!\n",
    "w = (np.array(eig_pairs[0][1]))\n",
    "#Matrix W\n",
    "print(\"Matrix W is: \\n\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated threshold is:  219.47634026257913\n"
     ]
    }
   ],
   "source": [
    "#Transforming the samples onto the new subspace\n",
    "#Project the means and take their mean; We multiply w by -1, i.e. -w, to get positive threshold!\n",
    "tot = 0\n",
    "for mean in class_means:\n",
    "    tot += np.dot(-w, mean)\n",
    "    #print(tot)\n",
    "w0 = 0.5 * tot\n",
    "print(\"Calculated threshold is: \", w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([170.39257328, 172.95820918, 170.42164701, 152.58704571,\n",
       "       162.72473931, 155.12018434, 201.01772525, 155.12702766,\n",
       "       180.59525765, 167.88679661, 152.59217349, 180.63801047,\n",
       "       183.12668828, 139.88713598, 162.75039327, 165.32971203,\n",
       "       165.32971203, 180.57815502, 172.94110654, 180.59867742,\n",
       "       170.39599305, 178.04330084, 173.00096577, 183.15234223,\n",
       "       180.6551131 , 165.29379498, 170.37717865, 167.83206516,\n",
       "       160.26685077, 157.67726892, 180.60380897, 162.74184195,\n",
       "       162.7367104 , 175.49305958, 190.84069484, 165.35536598,\n",
       "       170.41822723, 165.31260939, 190.90909406, 145.01840778,\n",
       "       172.94965786, 185.7231059 , 172.92742368, 157.72686882,\n",
       "       173.04371858, 188.26650762, 160.2326455 , 185.70087549,\n",
       "       167.8354887 , 172.93255523, 183.23785163, 160.22067064,\n",
       "       165.32971203, 190.88345519, 175.50674244, 183.28914823,\n",
       "       175.54949526, 157.65845829, 162.77262745, 160.24119682,\n",
       "       198.44353804, 160.21554287, 185.89756333, 175.47253717,\n",
       "       160.22409418, 160.26685077, 160.24461659, 178.13223379,\n",
       "       175.54607549, 155.11847634, 165.29037521, 183.24640295,\n",
       "       175.51529376, 178.0552757 , 170.39257328, 162.78973008,\n",
       "       178.11513116, 180.55592084, 183.18312396, 167.84916779,\n",
       "       167.88679661, 180.5696037 , 172.94965786, 170.42677855,\n",
       "       170.42677855, 175.58883207, 167.85259134, 180.59183411,\n",
       "       165.31260939, 157.68411224, 165.3023463 , 172.99241445,\n",
       "       170.41822723, 160.21554287, 162.77262745, 155.1013737 ,\n",
       "       157.69437156, 160.30105604, 178.08434943, 185.84624789,\n",
       "       188.43754528, 200.96641735, 180.63801047, 160.22409418,\n",
       "       185.63246495, 178.06553502, 190.81504088, 157.70121487,\n",
       "       170.41822723, 165.30405807, 167.87824529, 175.52384508,\n",
       "       152.57849439, 170.39257328, 165.29550676, 167.86114265,\n",
       "       175.54949526, 185.84112011, 188.25282853, 165.35023443,\n",
       "       157.71831751, 162.76407613, 160.20699155, 165.29550676,\n",
       "       155.13557897, 185.70087549, 188.26650762, 183.18996727,\n",
       "       165.32116071, 185.69232418, 188.28361025, 190.80648957,\n",
       "       178.08092966, 157.71831751, 173.00096577, 144.99275383,\n",
       "       183.15234223, 167.85771911, 165.29550676, 160.24974813,\n",
       "       167.84061648, 188.18099822, 162.78117876, 170.41822723,\n",
       "       180.63630247, 152.6007248 , 165.32628848, 157.66187806,\n",
       "       162.80683271, 167.89534792, 180.6209116 , 175.5033189 ,\n",
       "       178.06382702, 162.79485785, 157.7302886 , 195.99761681,\n",
       "       157.70121487, 175.48963981, 178.0552757 , 180.5696037 ,\n",
       "       183.15234223, 172.90690128, 175.52384508, 160.1830456 ,\n",
       "       165.33826334, 170.38402196, 170.4011246 , 185.68377286,\n",
       "       160.19844023, 185.69232418, 160.21041132, 172.93255523,\n",
       "       175.48450826, 175.55804658, 160.27540209, 162.73842218,\n",
       "       175.48963981, 160.24803636, 162.75552481, 160.22922196,\n",
       "       170.46953137, 180.61578006, 172.95820918, 162.75552481,\n",
       "       185.76928226, 172.94110654, 170.42677855, 155.15268161,\n",
       "       175.56659789, 167.86969397, 162.7982814 , 193.35502283,\n",
       "       162.78973008, 160.23606527, 157.67556092, 157.70976619,\n",
       "       180.58157479, 170.41822723, 172.94965786, 180.64314201,\n",
       "       170.40967592, 162.77604722, 178.06040348, 157.6670096 ,\n",
       "       185.70087549, 200.94076717, 190.77228807, 180.62945915,\n",
       "       165.29892653, 178.11513116])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Error\n",
    "#For each input project the point\n",
    "features = data[:, 1:]\n",
    "labels = data[:,0]\n",
    "projected = np.zeros((int(features.shape[0])))\n",
    "for i in range(int(features.shape[0])):\n",
    "    projected[i] = np.dot(-w, features[i].T).T\n",
    "projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign Predictions\n",
    "predictions = []\n",
    "for item in projected:\n",
    "    if item >= w0:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(2)\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate is:  34.76190476190476 %\n"
     ]
    }
   ],
   "source": [
    "#Check Classification\n",
    "errors = (labels != predictions)\n",
    "n_errors = sum(errors)\n",
    "\n",
    "error_rate = (n_errors/len(predictions) * 100)\n",
    "print(\"Error Rate is: \", error_rate, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my case I was predicted as:  Female  which is  False\n"
     ]
    }
   ],
   "source": [
    "#My case\n",
    "my_height = 164\n",
    "my_weight = 65\n",
    "my_features = np.array([my_height, my_weight*my_height])\n",
    "my_ground_truth = \"Male\"\n",
    "\n",
    "#My Prediction\n",
    "my_projection = np.dot(w, my_features.T).T\n",
    "if my_projection >= w0:\n",
    "    my_pred = \"Male\"\n",
    "else:\n",
    "    my_pred = \"Female\"\n",
    "\n",
    "print(\"In my case I was predicted as: \", my_pred, \" which is \", my_ground_truth==my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sebastianraschka.com/Articles/2014_python_lda.html\n",
    "\n",
    "http://goelhardik.github.io/2016/10/04/fishers-lda/\n",
    "\n",
    "https://www.python-course.eu/linear_discriminant_analysis.php\n",
    "\n",
    "https://github.com/goelhardik/projects/blob/master/fishers_lda/lda.py\n",
    "\n",
    "https://scikit-learn.org/stable/modules/lda_qda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}\n",
      "[2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 1. 1. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 1.\n",
      " 1. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 1. 2. 1.\n",
      " 2. 2. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 1. 1. 2. 2. 1.\n",
      " 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2.\n",
      " 2. 2. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 1.\n",
      " 2. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 2. 2. 1.\n",
      " 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 1. 1. 1. 1. 2. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(features, labels)\n",
    "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
    "              solver='eigen', store_covariance=False, tol=0.0001)\n",
    "print(clf.get_params())\n",
    "print(clf.predict(features))\n",
    "sum(labels!=clf.predict(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.904761904761903"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (25/210)*100\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
